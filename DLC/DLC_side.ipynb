{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='side_cameras'\n",
    "experimenter='Devon'\n",
    "train_set='C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\side_camera_training_set'\n",
    "working_dir = 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\labeled-data\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\training-datasets\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\"\n",
      "6  videos from the directory C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set were added to the project.\n",
      "Copying the videos\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\1.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\2.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\3.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\4.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\5.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\videos\\6.MOV\n",
      "Generated \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\config.yaml\"\n",
      "\n",
      "A new project with name side_cameras-Devon-2021-03-10 is created at C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "config_path = deeplabcut.create_new_project(project_name,\n",
    "                                            experimenter,\n",
    "                                            [train_set],\n",
    "                                           working_directory=working_dir,\n",
    "                                            videotype='.MOV',\n",
    "                                           copy_videos=True,\n",
    "                                           multianimal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for side camera, config path is\n",
    "config_path=r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting for now!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new frames..\n",
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\labeled-data\\2\\img1741.png\n",
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\labeled-data\\2\\img1742.png\n",
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\labeled-data\\2\\img1743.png\n",
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Devon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/215 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 215/215 [00:47<00:00,  4.55it/s]\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 108/108 [00:23<00:00,  4.69it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.71it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 11/11 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\training-datasets\\iteration-0\\UnaugmentedDataSet_side_camerasMar10  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\\iteration-0\\side_camerasMar10-trainset95shuffle1  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\\iteration-0\\side_camerasMar10-trainset95shuffle1/train  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\\iteration-0\\side_camerasMar10-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([343, 287,  33, 198, 121,  56,  93, 306, 232, 123,  24, 173, 266,\n",
       "          244, 146, 192, 310, 183,  26, 255, 271, 112,  67,  73, 129, 206,\n",
       "          281, 238, 331, 175, 133, 174, 290, 216, 188, 144, 217, 325, 108,\n",
       "          329, 345, 265,  80, 199,  62, 103, 120,  23, 114, 161, 177,  98,\n",
       "          246,  46, 136, 296, 249, 262, 147,  82,  90, 117, 280, 228, 215,\n",
       "          267, 312, 223, 314, 167, 326, 344,  79, 231, 236, 297, 204, 131,\n",
       "          165, 300, 213,  27, 254, 284, 282, 313,  68, 107, 275, 294,  34,\n",
       "          332, 176, 334,  97,  54, 186, 143, 196, 339,  84, 134,  29, 305,\n",
       "          321, 247, 227, 189, 340,  48, 210, 130, 270, 298, 347,  35,  43,\n",
       "          148, 172, 221, 218, 253, 127,  64, 288, 220, 166,   9, 311,  49,\n",
       "           52,  42,  19,  70,  13, 142, 152, 195, 301, 252,  61,  60, 122,\n",
       "           71, 257, 241,  65,  69, 315,  32, 320, 113, 135, 277,  85,  11,\n",
       "          193,  22, 304, 224, 164,  92, 269, 309, 153, 274, 225,  77, 276,\n",
       "           63, 132,  37, 159,  86,   2, 292,  28,  30, 240, 201, 170,  51,\n",
       "          157, 104,  78, 197, 222,  87, 283, 291,  99, 190, 308,  41, 126,\n",
       "           76, 323,  36,  55, 348, 229, 234, 279, 258, 156, 230, 273, 125,\n",
       "           45, 335, 185, 209,  88,  91, 212, 322, 226, 260, 181,   8, 233,\n",
       "          286, 307, 160, 327, 111,  10,  21, 100, 162, 328, 289, 137, 194,\n",
       "          303, 179, 150,  47,   3, 264, 285,   4, 178, 106, 272,  44, 139,\n",
       "          338,  57, 250, 211, 149,  20, 115,  31, 342,  72,  58, 237,  15,\n",
       "          110,  17, 316, 191, 324, 141, 261, 256, 140, 154,  74,   0, 319,\n",
       "           83, 259, 330,   1,  94, 333, 268,  75,  16, 168, 119, 101,   6,\n",
       "          163, 145, 346,  25, 151, 263, 336,   5, 251, 239, 235, 318, 105,\n",
       "          118,  95, 317, 158,   7, 341, 299, 208, 248, 207, 243, 169, 116,\n",
       "           39, 278, 295, 102, 138, 245, 184, 124, 205, 180, 242,  81, 302,\n",
       "           14, 182, 200, 155,  38,  53]),\n",
       "   array([293,  12,  89, 109,  96,  66,  40,  18, 171, 202, 128, 337,  59,\n",
       "          187, 203,  50, 219, 214])))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\side_cameras_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\Documentation_data-side_cameras_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10\\\\dlc-models\\\\iteration-0\\\\side_camerasMar10-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Max_iters overwritten as 60000\n",
      "Display_iters overwritten as 1200\n",
      "Save_iters overwritten as 1200\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10\\\\dlc-models\\\\iteration-0\\\\side_camerasMar10-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5]], 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase', 'leftarm', 'rightarm'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\side_cameras_Devon95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\Documentation_data-side_cameras_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 6, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1200 loss: 0.0223 lr: 0.005\n",
      "iteration: 2400 loss: 0.0160 lr: 0.005\n",
      "iteration: 3600 loss: 0.0145 lr: 0.005\n",
      "iteration: 4800 loss: 0.0132 lr: 0.005\n",
      "iteration: 6000 loss: 0.0124 lr: 0.005\n",
      "iteration: 7200 loss: 0.0122 lr: 0.005\n",
      "iteration: 8400 loss: 0.0113 lr: 0.005\n",
      "iteration: 9600 loss: 0.0110 lr: 0.005\n",
      "iteration: 10800 loss: 0.0127 lr: 0.02\n",
      "iteration: 12000 loss: 0.0123 lr: 0.02\n",
      "iteration: 13200 loss: 0.0114 lr: 0.02\n",
      "iteration: 14400 loss: 0.0105 lr: 0.02\n",
      "iteration: 15600 loss: 0.0098 lr: 0.02\n",
      "iteration: 16800 loss: 0.0096 lr: 0.02\n",
      "iteration: 18000 loss: 0.0088 lr: 0.02\n",
      "iteration: 19200 loss: 0.0088 lr: 0.02\n",
      "iteration: 20400 loss: 0.0082 lr: 0.02\n",
      "iteration: 21600 loss: 0.0077 lr: 0.02\n",
      "iteration: 22800 loss: 0.0078 lr: 0.02\n",
      "iteration: 24000 loss: 0.0076 lr: 0.02\n",
      "iteration: 25200 loss: 0.0073 lr: 0.02\n",
      "iteration: 26400 loss: 0.0068 lr: 0.02\n",
      "iteration: 27600 loss: 0.0071 lr: 0.02\n",
      "iteration: 28800 loss: 0.0065 lr: 0.02\n",
      "iteration: 30000 loss: 0.0065 lr: 0.02\n",
      "iteration: 31200 loss: 0.0061 lr: 0.02\n",
      "iteration: 32400 loss: 0.0063 lr: 0.02\n",
      "iteration: 33600 loss: 0.0061 lr: 0.02\n",
      "iteration: 34800 loss: 0.0059 lr: 0.02\n",
      "iteration: 36000 loss: 0.0059 lr: 0.02\n",
      "iteration: 37200 loss: 0.0058 lr: 0.02\n",
      "iteration: 38400 loss: 0.0057 lr: 0.02\n",
      "iteration: 39600 loss: 0.0053 lr: 0.02\n",
      "iteration: 40800 loss: 0.0053 lr: 0.02\n",
      "iteration: 42000 loss: 0.0052 lr: 0.02\n",
      "iteration: 43200 loss: 0.0052 lr: 0.02\n",
      "iteration: 44400 loss: 0.0051 lr: 0.02\n",
      "iteration: 45600 loss: 0.0053 lr: 0.02\n",
      "iteration: 46800 loss: 0.0050 lr: 0.02\n",
      "iteration: 48000 loss: 0.0047 lr: 0.02\n",
      "iteration: 49200 loss: 0.0048 lr: 0.02\n",
      "iteration: 50400 loss: 0.0047 lr: 0.02\n",
      "iteration: 51600 loss: 0.0047 lr: 0.02\n",
      "iteration: 52800 loss: 0.0046 lr: 0.02\n",
      "iteration: 54000 loss: 0.0045 lr: 0.02\n",
      "iteration: 55200 loss: 0.0044 lr: 0.02\n",
      "iteration: 56400 loss: 0.0045 lr: 0.02\n",
      "iteration: 57600 loss: 0.0044 lr: 0.02\n",
      "iteration: 58800 loss: 0.0042 lr: 0.02\n",
      "iteration: 60000 loss: 0.0043 lr: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2878, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-8a434a1a9ce7>\", line 7, in <module>\n",
      "    gputouse=0)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4555, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path,\n",
    "                        maxiters=60000,\n",
    "                        shuffle=1,\n",
    "                        max_snapshots_to_keep=10,\n",
    "                        saveiters=1200,\n",
    "                        displayiters=1200,\n",
    "                        gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\side_cameras_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10\\\\dlc-models\\\\iteration-0\\\\side_camerasMar10-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10/evaluation-results/  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\evaluation-results\\iteration-0\\side_camerasMar10-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_side_camerasMar10shuffle1_60000  with # of trainingiterations: 60000\n",
      "This net has already been evaluated!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_video1 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\1.MOV'\n",
    "novel_video2 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\2.MOV'\n",
    "novel_video3 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\3.MOV'\n",
    "novel_video4 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\4.MOV'\n",
    "novel_video5 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\5.MOV'\n",
    "novel_video6 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\6.MOV'\n",
    "\n",
    "novel_videos=[novel_video1,novel_video2,novel_video3,novel_video4,novel_video5,novel_video6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\side_cameras_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10\\\\dlc-models\\\\iteration-0\\\\side_camerasMar10-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\\iteration-0\\side_camerasMar10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\1.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\1.MOV\n",
      "Duration of video [s]:  155.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2331  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:07, 12.16it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:09, 12.41it/s]\n",
      "  0%|          | 0/2328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\2.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\2.MOV\n",
      "Duration of video [s]:  155.2 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2328  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:07, 12.48it/s]                          \n",
      "  0%|          | 0/2310 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2328\n",
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\3.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\3.MOV\n",
      "Duration of video [s]:  154.0 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2310  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:07, 12.07it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:08, 12.32it/s]\n",
      "  0%|          | 0/2745 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\4.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\4.MOV\n",
      "Duration of video [s]:  183.0 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2745  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754it [03:43, 12.58it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754it [03:46, 12.18it/s]\n",
      "  0%|          | 0/2737 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\5.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\5.MOV\n",
      "Duration of video [s]:  182.47 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2737  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754it [03:43, 12.77it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754it [03:44, 12.24it/s]\n",
      "  0%|          | 0/2752 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\6.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\6.MOV\n",
      "Duration of video [s]:  183.47 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2752  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2754it [03:45, 12.21it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2752\n",
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_side_camerasMar10shuffle1_60000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path,\n",
    "                          novel_videos,\n",
    "                          save_as_csv=True,\n",
    "                          videotype='mov',\n",
    "                         shuffle=1,\n",
    "                         gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\1.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\2.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\3.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\4.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\5.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set\\6.MOV and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.plot_trajectories(config_path, novel_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path,novel_videos,save_frames=False,trailpoints=1,videotype='mov',draw_skeleton='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# test on one set of videos\n",
    "# top camera dlc config\n",
    "top_config  = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\config.yaml'\n",
    "# side camera dlc config\n",
    "side_config = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\config.yaml'\n",
    "\n",
    "root_path = r'D:\\Desktop\\2021-03-09_h5-2053'\n",
    "top_video = os.path.join(root_path,'processed','undistorted_camera_17391304.MOV')\n",
    "side_videos = [os.path.join(root_path,'processed','undistorted_camera_17391290.MOV'),\n",
    "            os.path.join(root_path,'processed','undistorted_camera_19287342.MOV'),\n",
    "            os.path.join(root_path,'processed','undistorted_camera_19412282.MOV')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Alec_second_try_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07\\\\dlc-models\\\\iteration-0\\\\Alec_second_tryDec7-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-186000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_second_tryDec7-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_17391304.MOV\n",
      "D:\\Desktop\\2021-03-09_h5-2053\\processed  already exists!\n",
      "Loading  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_17391304.MOV\n",
      "Duration of video [s]:  153.73 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2306  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:09, 12.22it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:10, 12.16it/s]\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_camerasMar10\\\\side_cameras_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras-Devon-2021-03-10\\\\dlc-models\\\\iteration-0\\\\side_camerasMar10-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\Desktop\\2021-03-09_h5-2053\\processed...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras-Devon-2021-03-10\\dlc-models\\iteration-0\\side_camerasMar10-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_17391290.MOV\n",
      "D:\\Desktop\\2021-03-09_h5-2053\\processed  already exists!\n",
      "Loading  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_17391290.MOV\n",
      "Duration of video [s]:  155.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2331  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:08, 12.01it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:10, 12.34it/s]\n",
      "  0%|          | 0/2328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\Desktop\\2021-03-09_h5-2053\\processed...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_19287342.MOV\n",
      "D:\\Desktop\\2021-03-09_h5-2053\\processed  already exists!\n",
      "Loading  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_19287342.MOV\n",
      "Duration of video [s]:  155.2 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2328  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:11, 12.27it/s]                          \n",
      "  0%|          | 0/2310 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2328\n",
      "Saving results in D:\\Desktop\\2021-03-09_h5-2053\\processed...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_19412282.MOV\n",
      "D:\\Desktop\\2021-03-09_h5-2053\\processed  already exists!\n",
      "Loading  D:\\Desktop\\2021-03-09_h5-2053\\processed\\undistorted_camera_19412282.MOV\n",
      "Duration of video [s]:  154.0 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2310  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:10, 11.99it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2323it [03:11, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\Desktop\\2021-03-09_h5-2053\\processed...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_side_camerasMar10shuffle1_60000'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzing top camera\n",
    "deeplabcut.analyze_videos(top_config,\n",
    "                          top_video,\n",
    "                          save_as_csv=True,\n",
    "                          videotype='mov',\n",
    "                         shuffle=1,\n",
    "                         gputouse=0)\n",
    "# analyzing side cameras\n",
    "deeplabcut.analyze_videos(side_config,\n",
    "                          side_videos,\n",
    "                          save_as_csv=True,\n",
    "                          videotype='mov',\n",
    "                         shuffle=1,\n",
    "                         gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(top_config,\n",
    "                                top_video,\n",
    "                                save_frames=False,\n",
    "                                trailpoints=1,\n",
    "                                videotype='mov',\n",
    "                                draw_skeleton='True')\n",
    "deeplabcut.create_labeled_video(side_config,\n",
    "                                side_videos,\n",
    "                                save_frames=False,\n",
    "                                trailpoints=1,\n",
    "                                videotype='mov',\n",
    "                                draw_skeleton='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
