{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='side_cameras_distorted'\n",
    "experimenter='Devon'\n",
    "train_set='C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\side_camera_training_set_distorted'\n",
    "working_dir = 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\labeled-data\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\training-datasets\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\dlc-models\"\n",
      "6  videos from the directory C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted were added to the project.\n",
      "Copying the videos\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\1.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\2.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\3.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\4.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\5.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\videos\\6.MOV\n",
      "Generated \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\config.yaml\"\n",
      "\n",
      "A new project with name side_cameras_distorted-Devon-2021-03-17 is created at C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "config_path = deeplabcut.create_new_project(project_name,\n",
    "                                            experimenter,\n",
    "                                            [train_set],\n",
    "                                           working_directory=working_dir,\n",
    "                                            videotype='.MOV',\n",
    "                                           copy_videos=True,\n",
    "                                           multianimal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for side camera, config path is\n",
    "config_path=r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 68.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 157.53  seconds.\n",
      "Extracting and downsampling... 2363  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2363it [00:23, 99.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 47.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 152.33  seconds.\n",
      "Extracting and downsampling... 2285  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2285it [00:22, 100.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 149.93  seconds.\n",
      "Extracting and downsampling... 2249  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2249it [00:22, 101.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 59.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 160.4  seconds.\n",
      "Extracting and downsampling... 2406  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2406it [00:23, 101.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 49.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 159.93  seconds.\n",
      "Extracting and downsampling... 2399  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2399it [00:24, 99.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 58.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 165.2  seconds.\n",
      "Extracting and downsampling... 2478  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2478it [00:25, 98.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 57.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 145.87  seconds.\n",
      "Extracting and downsampling... 2188  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2188it [00:22, 98.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 55.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 144.27  seconds.\n",
      "Extracting and downsampling... 2164  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2164it [00:22, 98.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos of interest.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\labeled-data\\16\\img1326.png\n",
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\labeled-data\\16\\img1556.png\n",
      "Delete Image Path :  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\labeled-data\\17\\img1842.png\n",
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Devon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 37/37 [00:10<00:00,  3.60it/s]\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.46it/s]\n",
      "100%|██████████| 31/31 [00:08<00:00,  3.67it/s]\n",
      "100%|██████████| 32/32 [00:09<00:00,  3.37it/s]\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.60it/s]\n",
      "100%|██████████| 33/33 [00:09<00:00,  3.61it/s]\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.61it/s]\n",
      "100%|██████████| 34/34 [00:09<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 72, 230,  70, 180, 232, 179,  23, 450, 473, 278, 359, 393, 247,\n",
       "          109,  64, 434, 325, 491, 154, 397,  78, 431, 451, 293, 388, 382,\n",
       "          149, 489, 131, 386, 339, 268, 392, 188, 361,  67,   6, 307,   5,\n",
       "          148, 250, 384, 390, 208, 446, 116, 486, 410, 439, 435, 480, 301,\n",
       "          329, 159, 229, 304, 100, 438,  80, 355, 367, 468, 136, 494, 445,\n",
       "          128, 463, 432, 455, 493, 210, 327,  89, 105, 108, 340, 427, 282,\n",
       "          257, 271, 402, 231, 374, 119, 414, 370,   3, 182, 387,  99, 449,\n",
       "           38,  66, 166, 333, 233, 399, 394, 420, 285, 308,  88, 239, 118,\n",
       "          224, 190, 227,  29,  61, 366, 447, 364,  59, 458, 490, 444, 483,\n",
       "          344, 178,  84, 241, 260, 360,  22, 348, 249, 234, 378, 497,  18,\n",
       "          416,  54, 425,  86, 244,  94, 412, 356,  82, 404, 341,  96, 145,\n",
       "          475, 121, 371, 331, 317, 424, 113, 222,  73, 411, 284, 185, 336,\n",
       "          398, 120, 134, 368,  71, 115,   7, 332,  47, 237, 281,  30, 106,\n",
       "          286, 379, 265, 369,  19, 464, 221,  51,  48, 488, 213, 181, 176,\n",
       "          357, 362, 326, 469, 310, 373, 147, 408, 133, 465, 429,  56, 441,\n",
       "          487, 346, 297, 330, 375,  68, 201, 478, 228, 385, 267, 262, 470,\n",
       "          199, 456, 302,  26, 338, 459, 335, 254, 403, 146, 137,  95,  34,\n",
       "          277, 220, 315,  81, 389, 255, 143,  20,  21, 138, 264, 245, 164,\n",
       "          318, 151, 107, 158, 235, 275, 177, 406, 365, 104, 258,  13, 194,\n",
       "          272,  49, 461, 345, 418, 112, 225,  58, 214, 479, 295, 381, 380,\n",
       "          320, 129, 290, 306, 337,   0,  57,  27, 246, 163, 376,  28,  53,\n",
       "          223, 334,  10,  93, 288, 433,  79, 303,  63, 351,  77,  52,  50,\n",
       "           17, 358, 186, 212, 135, 454, 328, 157, 474, 171, 110, 269, 413,\n",
       "          114, 198, 253,   9, 291, 350, 266, 207,  43, 242, 299,  39, 323,\n",
       "          422, 170, 437, 111, 218, 395, 139,  98, 263,   1, 122, 101, 426,\n",
       "           92,  42,  14,  62,  87, 219, 343, 217, 127,  55, 436, 169, 141,\n",
       "          150, 305, 462, 349, 280,  12, 443,  83, 144,  24, 423, 314, 202,\n",
       "          363, 236,  44, 132, 324, 259, 184, 187, 294, 292,  46, 419, 289,\n",
       "          130,  36, 313,  37, 298, 283, 195, 124, 440, 372, 401, 206, 405,\n",
       "          273, 172,   8,  90, 453, 156,  35, 296,  32,  45, 321, 142,  65,\n",
       "          319, 192,  33, 117, 197, 481, 140,  69, 123, 342, 238, 452, 477,\n",
       "           74, 175, 409,  41,  85, 352, 252, 448, 153, 209, 417, 160, 174,\n",
       "          492, 312, 211, 161, 167,  25, 309, 196,  91, 383, 165,  11, 125,\n",
       "          193, 173,  15, 415, 248, 226, 353, 471, 457, 482, 102, 189, 300,\n",
       "          240, 460, 495, 261, 476, 407, 215,  97, 391, 466, 274, 396, 205,\n",
       "           60,  40, 126, 276, 152, 354, 442, 203, 251,  31, 183, 191, 430,\n",
       "            4, 485, 421, 256, 200]),\n",
       "   array([322, 400, 270, 162, 204, 311, 155, 279, 216, 243,  75, 347, 103,\n",
       "           16, 168,   2, 428, 496, 484, 316, 287, 467, 377, 472,  76])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\side_cameras_distorted_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\Documentation_data-side_cameras_distorted_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17\\\\dlc-models\\\\iteration-0\\\\side_cameras_distortedMar17-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Max_iters overwritten as 200000\n",
      "Display_iters overwritten as 2000\n",
      "Save_iters overwritten as 2000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17\\\\dlc-models\\\\iteration-0\\\\side_cameras_distortedMar17-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5]], 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase', 'leftarm', 'rightarm'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\side_cameras_distorted_Devon95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\Documentation_data-side_cameras_distorted_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 6, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 2000 loss: 0.0226 lr: 0.005\n",
      "iteration: 4000 loss: 0.0176 lr: 0.005\n",
      "iteration: 6000 loss: 0.0153 lr: 0.005\n",
      "iteration: 8000 loss: 0.0138 lr: 0.005\n",
      "iteration: 10000 loss: 0.0131 lr: 0.005\n",
      "iteration: 12000 loss: 0.0156 lr: 0.02\n",
      "iteration: 14000 loss: 0.0134 lr: 0.02\n",
      "iteration: 16000 loss: 0.0123 lr: 0.02\n",
      "iteration: 18000 loss: 0.0116 lr: 0.02\n",
      "iteration: 20000 loss: 0.0107 lr: 0.02\n",
      "iteration: 22000 loss: 0.0102 lr: 0.02\n",
      "iteration: 24000 loss: 0.0098 lr: 0.02\n",
      "iteration: 26000 loss: 0.0094 lr: 0.02\n",
      "iteration: 28000 loss: 0.0089 lr: 0.02\n",
      "iteration: 30000 loss: 0.0085 lr: 0.02\n",
      "iteration: 32000 loss: 0.0082 lr: 0.02\n",
      "iteration: 34000 loss: 0.0081 lr: 0.02\n",
      "iteration: 36000 loss: 0.0078 lr: 0.02\n",
      "iteration: 38000 loss: 0.0075 lr: 0.02\n",
      "iteration: 40000 loss: 0.0073 lr: 0.02\n",
      "iteration: 42000 loss: 0.0069 lr: 0.02\n",
      "iteration: 44000 loss: 0.0068 lr: 0.02\n",
      "iteration: 46000 loss: 0.0067 lr: 0.02\n",
      "iteration: 48000 loss: 0.0065 lr: 0.02\n",
      "iteration: 50000 loss: 0.0062 lr: 0.02\n",
      "iteration: 52000 loss: 0.0063 lr: 0.02\n",
      "iteration: 54000 loss: 0.0062 lr: 0.02\n",
      "iteration: 56000 loss: 0.0058 lr: 0.02\n",
      "iteration: 58000 loss: 0.0059 lr: 0.02\n",
      "iteration: 60000 loss: 0.0057 lr: 0.02\n",
      "iteration: 62000 loss: 0.0059 lr: 0.02\n",
      "iteration: 64000 loss: 0.0056 lr: 0.02\n",
      "iteration: 66000 loss: 0.0055 lr: 0.02\n",
      "iteration: 68000 loss: 0.0053 lr: 0.02\n",
      "iteration: 70000 loss: 0.0051 lr: 0.02\n",
      "iteration: 72000 loss: 0.0051 lr: 0.02\n",
      "iteration: 74000 loss: 0.0049 lr: 0.02\n",
      "iteration: 76000 loss: 0.0049 lr: 0.02\n",
      "iteration: 78000 loss: 0.0049 lr: 0.02\n",
      "iteration: 80000 loss: 0.0049 lr: 0.02\n",
      "iteration: 82000 loss: 0.0046 lr: 0.02\n",
      "iteration: 84000 loss: 0.0045 lr: 0.02\n",
      "iteration: 86000 loss: 0.0045 lr: 0.02\n",
      "iteration: 88000 loss: 0.0046 lr: 0.02\n",
      "iteration: 90000 loss: 0.0046 lr: 0.02\n",
      "iteration: 92000 loss: 0.0044 lr: 0.02\n",
      "iteration: 94000 loss: 0.0044 lr: 0.02\n",
      "iteration: 96000 loss: 0.0043 lr: 0.02\n",
      "iteration: 98000 loss: 0.0043 lr: 0.02\n",
      "iteration: 100000 loss: 0.0042 lr: 0.02\n",
      "iteration: 102000 loss: 0.0042 lr: 0.02\n",
      "iteration: 104000 loss: 0.0041 lr: 0.02\n",
      "iteration: 106000 loss: 0.0041 lr: 0.02\n",
      "iteration: 108000 loss: 0.0041 lr: 0.02\n",
      "iteration: 110000 loss: 0.0040 lr: 0.02\n",
      "iteration: 112000 loss: 0.0039 lr: 0.02\n",
      "iteration: 114000 loss: 0.0039 lr: 0.02\n",
      "iteration: 116000 loss: 0.0038 lr: 0.02\n",
      "iteration: 118000 loss: 0.0039 lr: 0.02\n",
      "iteration: 120000 loss: 0.0037 lr: 0.02\n",
      "iteration: 122000 loss: 0.0037 lr: 0.02\n",
      "iteration: 124000 loss: 0.0036 lr: 0.02\n",
      "iteration: 126000 loss: 0.0037 lr: 0.02\n",
      "iteration: 128000 loss: 0.0037 lr: 0.02\n",
      "iteration: 130000 loss: 0.0035 lr: 0.02\n",
      "iteration: 132000 loss: 0.0037 lr: 0.02\n",
      "iteration: 134000 loss: 0.0034 lr: 0.02\n",
      "iteration: 136000 loss: 0.0035 lr: 0.02\n",
      "iteration: 138000 loss: 0.0034 lr: 0.02\n",
      "iteration: 140000 loss: 0.0034 lr: 0.02\n",
      "iteration: 142000 loss: 0.0034 lr: 0.02\n",
      "iteration: 144000 loss: 0.0034 lr: 0.02\n",
      "iteration: 146000 loss: 0.0033 lr: 0.02\n",
      "iteration: 148000 loss: 0.0034 lr: 0.02\n",
      "iteration: 150000 loss: 0.0033 lr: 0.02\n",
      "iteration: 152000 loss: 0.0033 lr: 0.02\n",
      "iteration: 154000 loss: 0.0031 lr: 0.02\n",
      "iteration: 156000 loss: 0.0033 lr: 0.02\n",
      "iteration: 158000 loss: 0.0032 lr: 0.02\n",
      "iteration: 160000 loss: 0.0031 lr: 0.02\n",
      "iteration: 162000 loss: 0.0031 lr: 0.02\n",
      "iteration: 164000 loss: 0.0032 lr: 0.02\n",
      "iteration: 166000 loss: 0.0030 lr: 0.02\n",
      "iteration: 168000 loss: 0.0030 lr: 0.02\n",
      "iteration: 170000 loss: 0.0031 lr: 0.02\n",
      "iteration: 172000 loss: 0.0029 lr: 0.02\n",
      "iteration: 174000 loss: 0.0030 lr: 0.02\n",
      "iteration: 176000 loss: 0.0030 lr: 0.02\n",
      "iteration: 178000 loss: 0.0029 lr: 0.02\n",
      "iteration: 180000 loss: 0.0030 lr: 0.02\n",
      "iteration: 182000 loss: 0.0030 lr: 0.02\n",
      "iteration: 184000 loss: 0.0029 lr: 0.02\n",
      "iteration: 186000 loss: 0.0028 lr: 0.02\n",
      "iteration: 188000 loss: 0.0029 lr: 0.02\n",
      "iteration: 190000 loss: 0.0029 lr: 0.02\n",
      "iteration: 192000 loss: 0.0029 lr: 0.02\n",
      "iteration: 194000 loss: 0.0028 lr: 0.02\n",
      "iteration: 196000 loss: 0.0028 lr: 0.02\n",
      "iteration: 198000 loss: 0.0028 lr: 0.02\n",
      "iteration: 200000 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2878, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-8a38f48d8d9c>\", line 7, in <module>\n",
      "    gputouse=0)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4555, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path,\n",
    "                        maxiters=200000,\n",
    "                        shuffle=1,\n",
    "                        max_snapshots_to_keep=10,\n",
    "                        saveiters=2000,\n",
    "                        displayiters=2000,\n",
    "                        gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\side_cameras_distorted_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17\\\\dlc-models\\\\iteration-0\\\\side_cameras_distortedMar17-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17/evaluation-results/  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\evaluation-results\\iteration-0\\side_cameras_distortedMar17-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_side_cameras_distortedMar17shuffle1_200000  with # of trainingiterations: 200000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "498it [01:02,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-200000\n",
      "Results for 200000  training iterations: 95 1 train error: 6.28 pixels. Test error: 32.02  pixels.\n",
      "With pcutoff of 0.6  train error: 5.9 pixels. Test error: 12.58 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_video1 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\1.MOV'\n",
    "novel_video2 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\2.MOV'\n",
    "novel_video3 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\3.MOV'\n",
    "novel_video4 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\4.MOV'\n",
    "novel_video5 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\5.MOV'\n",
    "novel_video6 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\6.MOV'\n",
    "\n",
    "novel_videos=[novel_video1,novel_video2,novel_video3,novel_video4,novel_video5,novel_video6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'leftear',\n",
      "                      'rightear',\n",
      "                      'tailbase',\n",
      "                      'leftarm',\n",
      "                      'rightarm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_side_cameras_distortedMar17\\\\side_cameras_distorted_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\side_cameras_distorted-Devon-2021-03-17\\\\dlc-models\\\\iteration-0\\\\side_cameras_distortedMar17-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-120000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\side_cameras_distorted-Devon-2021-03-17\\dlc-models\\iteration-0\\side_cameras_distortedMar17-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\1.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\1.MOV\n",
      "Duration of video [s]:  155.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2331  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:08, 12.20it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:09, 12.35it/s]\n",
      "  0%|          | 0/2328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\2.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\2.MOV\n",
      "Duration of video [s]:  155.2 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2328  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:08, 12.48it/s]                          \n",
      "  0%|          | 0/2310 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2328\n",
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\3.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\3.MOV\n",
      "Duration of video [s]:  154.0 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2310  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:08, 12.11it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:09, 12.24it/s]\n",
      "  0%|          | 0/2331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\4.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\4.MOV\n",
      "Duration of video [s]:  155.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2331  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:10, 12.03it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:11, 12.27it/s]\n",
      "  0%|          | 0/2328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\5.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\5.MOV\n",
      "Duration of video [s]:  155.2 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2328  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2346it [03:10, 12.29it/s]                          \n",
      "  0%|          | 0/2310 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2328\n",
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\6.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\6.MOV\n",
      "Duration of video [s]:  154.0 , recorded with  15.0 fps!\n",
      "Overall # of frames:  2310  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2323it [03:08, 12.16it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2323it [03:09, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_side_cameras_distortedMar17shuffle1_120000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path,\n",
    "                          novel_videos,\n",
    "                          save_as_csv=True,\n",
    "                          videotype='mov',\n",
    "                         shuffle=1,\n",
    "                         gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\1.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\2.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\3.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\4.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\5.MOV and data.\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\side_camera_training_set_distorted\\6.MOV and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.plot_trajectories(config_path, novel_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path,novel_videos,save_frames=False,trailpoints=1,videotype='mov',draw_skeleton='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
