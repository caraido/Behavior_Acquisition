{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: create new project\n",
    "### config the project path and add videos (can be manually added after the project is created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='Alec_third_try_ma'\n",
    "experimenter='Devon'\n",
    "train_set='C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-07_Training_Video'\n",
    "working_dir = 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\videos\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\training-datasets\"\n",
      "Created \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\"\n",
      "4  videos from the directory C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-07_Training_Video were added to the project.\n",
      "Copying the videos\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\videos\\sa_1.mov\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\videos\\sa_3.mov\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\videos\\sa_4.mov\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\videos\\sa_5.mov\n",
      "Generated \"C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\config.yaml\"\n",
      "\n",
      "A new project with name Alec_third_try_ma-Devon-2020-12-07 is created at C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "config_path = deeplabcut.create_new_project(project_name,\n",
    "                                            experimenter,\n",
    "                                            [train_set],\n",
    "                                           working_directory=working_dir,\n",
    "                                            videotype='.mov',\n",
    "                                           copy_videos=True,\n",
    "                                           multianimal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print off config_path and record it for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all the configeration paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try\n",
    "#config_path=r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_first_try-Devon-2020-11-24\\config.yaml'\n",
    "\n",
    "# second try\n",
    "config_path=r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\config.yaml'\n",
    "\n",
    "# third try\n",
    "# config_path=r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 extract key frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 56.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 1848.96  seconds.\n",
      "Extracting and downsampling... 46224  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46224it [06:40, 115.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 59.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 317.44  seconds.\n",
      "Extracting and downsampling... 7936  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7936it [01:08, 115.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 45.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 309.84  seconds.\n",
      "Extracting and downsampling... 7746  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7746it [01:07, 115.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 317.56  seconds.\n",
      "Extracting and downsampling... 7939  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7939it [01:08, 115.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 68.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 319.8  seconds.\n",
      "Extracting and downsampling... 7995  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7995it [01:09, 115.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 58.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 314.24  seconds.\n",
      "Extracting and downsampling... 7856  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7856it [01:08, 115.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 60.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 326.64  seconds.\n",
      "Extracting and downsampling... 8166  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8166it [01:10, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 67.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 66.76  seconds.\n",
      "Extracting and downsampling... 1669  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1669it [00:14, 115.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 69.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 153.73  seconds.\n",
      "Extracting and downsampling... 2306  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2306it [00:20, 115.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 68.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 158.73  seconds.\n",
      "Extracting and downsampling... 2381  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2381it [00:20, 114.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 58.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 199.4  seconds.\n",
      "Extracting and downsampling... 2991  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2991it [00:25, 115.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 58.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 202.67  seconds.\n",
      "Extracting and downsampling... 3040  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3040it [00:26, 115.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 70.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 149.13  seconds.\n",
      "Extracting and downsampling... 2237  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2237it [00:19, 114.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos of interest.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 label the frames (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new frames..\n",
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the labels before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Devon.\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\sa_1_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/76 [00:00<?, ?it/s]C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\utils\\visualization.py:305: FutureWarning: Pass-through of possibly RGB images in gray2rgb is deprecated. In version 0.19, input arrays will always be considered grayscale, even if the last dimension has length 3 or 4. To prevent this warning and ensure compatibility with future versions, detect RGB images outside of this function.\n",
      "  im.set_data(color.gray2rgb(ic[i]))\n",
      "100%|██████████| 76/76 [00:23<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\sa_2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_1_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_3_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_4_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_5_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\ma_6_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:16<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\1_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\2_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\3_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\labeled-data\\4_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.21it/s]\n",
      "100%|██████████| 40/40 [00:12<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 create training dataset\n",
    "### for single animal project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\training-datasets\\iteration-0\\UnaugmentedDataSet_Alec_second_tryDec7  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([292,  22, 436, 278,   2, 217, 211,  78, 136,  17, 148, 508,  15,\n",
       "          110, 335, 182, 490, 320, 309,  62, 500,  10, 461, 331, 194, 297,\n",
       "          281, 414, 447, 251,  18, 218, 308, 542, 223, 165, 319, 202, 306,\n",
       "          520, 172, 228, 141, 545, 365, 355,  45,  70, 134, 249, 329, 193,\n",
       "          368,  47, 255, 321, 376, 507, 248, 431, 423,  60, 220, 195, 364,\n",
       "          473, 481, 420, 522, 191,  41, 403, 377,  84, 541,  95, 234,  98,\n",
       "          318, 181, 317, 474, 444, 256, 261,  53, 233,  32, 359, 245, 268,\n",
       "          344, 196, 518, 241,  20,  33, 142, 502, 310, 221, 425, 390, 343,\n",
       "           61, 113, 130, 517, 432, 279,  55,  91, 128, 519, 381, 103, 493,\n",
       "           66, 118, 109, 290, 155, 272, 307, 327, 328, 242, 302, 112,  57,\n",
       "          146,   3,  81,   0, 263, 239, 540, 415, 187, 230, 357, 237, 399,\n",
       "          459, 145,  14,  73, 465, 167, 463, 369, 426, 303, 301,   6, 360,\n",
       "          312, 295, 332, 229, 383, 235, 538, 324, 169,  88, 366, 275, 543,\n",
       "          455, 131, 482, 406, 190, 183, 408, 104, 313, 512, 346, 438, 494,\n",
       "          434, 140, 495, 153, 108, 203, 539, 486, 516,  97, 280,  96, 238,\n",
       "          296, 501, 362, 476, 449, 101,  24, 391, 487, 498, 243, 524, 454,\n",
       "          339,  44, 260, 351, 453, 530,  36, 485, 311, 392, 511, 204, 266,\n",
       "           19, 171, 277, 299, 450, 149,  26, 176, 206, 379, 460, 159, 254,\n",
       "          547,  37, 115, 129, 398, 363, 348, 207, 349, 510,  11, 521,  76,\n",
       "          326, 122, 342, 456,   9, 267, 361, 252,  85, 371,  65, 417, 373,\n",
       "          246,  83,  46, 546,  39, 257, 322,  56, 265, 397, 262, 158,   8,\n",
       "          505, 527,  31,  99, 448, 467, 139, 421,  35,  43, 374, 151, 286,\n",
       "          247, 157, 152, 430, 315,  48, 127,   7, 179, 162, 412, 259, 124,\n",
       "          226, 298, 428,  71, 400,  13, 372, 533,  27, 192, 404,  23, 352,\n",
       "          466, 200, 201,  72, 222, 442, 504, 164,  63, 506, 469, 537, 227,\n",
       "          405,  87, 525, 186, 534, 189, 401,  51, 483, 427, 451, 305, 499,\n",
       "          111,  89, 338,  94, 116,  82, 472, 283, 282, 178, 125, 350, 270,\n",
       "           52, 470, 386, 117, 120, 492, 271, 394, 285, 410,  68, 126, 166,\n",
       "          354, 291, 133, 341, 370, 445, 385, 529, 154, 523, 382, 389, 413,\n",
       "          188, 535, 288, 337,  90,  77, 231,  49,  80, 180, 147, 287, 106,\n",
       "          135, 384, 137, 446, 244, 143, 215,  58, 375, 114, 336, 544, 419,\n",
       "          489, 513, 208,  59, 433, 536, 269, 503, 378, 163, 429,  79, 380,\n",
       "          304, 205, 532, 224, 393, 274, 284, 174,  34, 402,  30,  50, 358,\n",
       "          334, 314, 197, 440, 468,  93,  74,   5, 185,  38, 395, 119, 443,\n",
       "          209, 416, 509, 353, 276, 471, 491, 105, 411, 240, 325, 488, 173,\n",
       "          177, 422, 345, 478, 184, 273, 323, 333,  12,  21,  42, 150, 293,\n",
       "          526, 161,  54, 464, 170, 300, 212, 458, 418,  16, 289, 531, 437,\n",
       "           40, 439,  75, 175,  64, 387,   4, 340, 475, 253, 214,  86,  28,\n",
       "          138, 132, 457, 441, 515, 144, 168, 477, 258, 435, 424, 347, 250,\n",
       "          232, 514, 107, 316, 121,  25, 264, 367, 210, 199,  92,  69, 330]),\n",
       "   array([236, 528, 102, 407,   1, 462, 356, 409, 100,  29, 480, 216, 123,\n",
       "          198, 479, 294, 156, 497, 396, 452, 496, 225, 388,  67, 213, 484,\n",
       "          219, 160])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for multi animal project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\sa_1 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:11<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\ma_4 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:32<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\ma_5 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:34<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\ma_6 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:36<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\ma_1 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:45<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to crop frames for folder:  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\labeled-data\\ma_2 ?\n",
      "(yes/no):yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:42<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.cropimagesandlabels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2370 [00:00<01:29, 26.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing the following graph: [[0, 1], [0, 2], [2, 1], [0, 3]]\n",
      "Creating training data for  1 0.95\n",
      "This can take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2370/2370 [01:42<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_multianimaltraining_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 train the network (usually with only one shuffle is enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Alec_second_try_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Documentation_data-Alec_second_try_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07\\\\dlc-models\\\\iteration-0\\\\Alec_second_tryDec7-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Max_iters overwritten as 200000\n",
      "Display_iters overwritten as 2400\n",
      "Save_iters overwritten as 2400\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07\\\\dlc-models\\\\iteration-0\\\\Alec_second_tryDec7-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Alec_second_try_Devon95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Documentation_data-Alec_second_try_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 2400 loss: 0.0176 lr: 0.005\n",
      "iteration: 4800 loss: 0.0100 lr: 0.005\n",
      "iteration: 7200 loss: 0.0081 lr: 0.005\n",
      "iteration: 9600 loss: 0.0071 lr: 0.005\n",
      "iteration: 12000 loss: 0.0077 lr: 0.02\n",
      "iteration: 14400 loss: 0.0059 lr: 0.02\n",
      "iteration: 16800 loss: 0.0052 lr: 0.02\n",
      "iteration: 19200 loss: 0.0046 lr: 0.02\n",
      "iteration: 21600 loss: 0.0041 lr: 0.02\n",
      "iteration: 24000 loss: 0.0038 lr: 0.02\n",
      "iteration: 26400 loss: 0.0036 lr: 0.02\n",
      "iteration: 28800 loss: 0.0034 lr: 0.02\n",
      "iteration: 31200 loss: 0.0033 lr: 0.02\n",
      "iteration: 33600 loss: 0.0031 lr: 0.02\n",
      "iteration: 36000 loss: 0.0031 lr: 0.02\n",
      "iteration: 38400 loss: 0.0029 lr: 0.02\n",
      "iteration: 40800 loss: 0.0029 lr: 0.02\n",
      "iteration: 43200 loss: 0.0028 lr: 0.02\n",
      "iteration: 45600 loss: 0.0027 lr: 0.02\n",
      "iteration: 48000 loss: 0.0026 lr: 0.02\n",
      "iteration: 50400 loss: 0.0026 lr: 0.02\n",
      "iteration: 52800 loss: 0.0026 lr: 0.02\n",
      "iteration: 55200 loss: 0.0025 lr: 0.02\n",
      "iteration: 57600 loss: 0.0024 lr: 0.02\n",
      "iteration: 60000 loss: 0.0024 lr: 0.02\n",
      "iteration: 62400 loss: 0.0024 lr: 0.02\n",
      "iteration: 64800 loss: 0.0024 lr: 0.02\n",
      "iteration: 67200 loss: 0.0024 lr: 0.02\n",
      "iteration: 69600 loss: 0.0023 lr: 0.02\n",
      "iteration: 72000 loss: 0.0023 lr: 0.02\n",
      "iteration: 74400 loss: 0.0023 lr: 0.02\n",
      "iteration: 76800 loss: 0.0022 lr: 0.02\n",
      "iteration: 79200 loss: 0.0023 lr: 0.02\n",
      "iteration: 81600 loss: 0.0022 lr: 0.02\n",
      "iteration: 84000 loss: 0.0022 lr: 0.02\n",
      "iteration: 86400 loss: 0.0021 lr: 0.02\n",
      "iteration: 88800 loss: 0.0021 lr: 0.02\n",
      "iteration: 91200 loss: 0.0022 lr: 0.02\n",
      "iteration: 93600 loss: 0.0021 lr: 0.02\n",
      "iteration: 96000 loss: 0.0021 lr: 0.02\n",
      "iteration: 98400 loss: 0.0021 lr: 0.02\n",
      "iteration: 100800 loss: 0.0020 lr: 0.02\n",
      "iteration: 103200 loss: 0.0020 lr: 0.02\n",
      "iteration: 105600 loss: 0.0020 lr: 0.02\n",
      "iteration: 108000 loss: 0.0020 lr: 0.02\n",
      "iteration: 110400 loss: 0.0020 lr: 0.02\n",
      "iteration: 112800 loss: 0.0020 lr: 0.02\n",
      "iteration: 115200 loss: 0.0020 lr: 0.02\n",
      "iteration: 117600 loss: 0.0020 lr: 0.02\n",
      "iteration: 120000 loss: 0.0020 lr: 0.02\n",
      "iteration: 122400 loss: 0.0020 lr: 0.02\n",
      "iteration: 124800 loss: 0.0019 lr: 0.02\n",
      "iteration: 127200 loss: 0.0019 lr: 0.02\n",
      "iteration: 129600 loss: 0.0019 lr: 0.02\n",
      "iteration: 132000 loss: 0.0019 lr: 0.02\n",
      "iteration: 134400 loss: 0.0019 lr: 0.02\n",
      "iteration: 136800 loss: 0.0019 lr: 0.02\n",
      "iteration: 139200 loss: 0.0019 lr: 0.02\n",
      "iteration: 141600 loss: 0.0019 lr: 0.02\n",
      "iteration: 144000 loss: 0.0019 lr: 0.02\n",
      "iteration: 146400 loss: 0.0019 lr: 0.02\n",
      "iteration: 148800 loss: 0.0018 lr: 0.02\n",
      "iteration: 151200 loss: 0.0019 lr: 0.02\n",
      "iteration: 153600 loss: 0.0018 lr: 0.02\n",
      "iteration: 156000 loss: 0.0018 lr: 0.02\n",
      "iteration: 158400 loss: 0.0018 lr: 0.02\n",
      "iteration: 160800 loss: 0.0019 lr: 0.02\n",
      "iteration: 163200 loss: 0.0018 lr: 0.02\n",
      "iteration: 165600 loss: 0.0018 lr: 0.02\n",
      "iteration: 168000 loss: 0.0018 lr: 0.02\n",
      "iteration: 170400 loss: 0.0018 lr: 0.02\n",
      "iteration: 172800 loss: 0.0018 lr: 0.02\n",
      "iteration: 175200 loss: 0.0018 lr: 0.02\n",
      "iteration: 177600 loss: 0.0018 lr: 0.02\n",
      "iteration: 180000 loss: 0.0018 lr: 0.02\n",
      "iteration: 182400 loss: 0.0018 lr: 0.02\n",
      "iteration: 184800 loss: 0.0018 lr: 0.02\n",
      "iteration: 187200 loss: 0.0017 lr: 0.02\n",
      "iteration: 189600 loss: 0.0018 lr: 0.02\n",
      "iteration: 192000 loss: 0.0018 lr: 0.02\n",
      "iteration: 194400 loss: 0.0017 lr: 0.02\n",
      "iteration: 196800 loss: 0.0017 lr: 0.02\n",
      "iteration: 199200 loss: 0.0018 lr: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 528, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\base_events.py\", line 1764, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2878, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-c2014ee1c3f9>\", line 7, in <module>\n",
      "    gputouse=0)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4555, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\SchwartzLab\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path,\n",
    "                        maxiters=200000,\n",
    "                        shuffle=1,\n",
    "                        max_snapshots_to_keep=10,\n",
    "                        saveiters=2400,\n",
    "                        displayiters=2400,\n",
    "                        gputouse=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['snout', 'leftear', 'rightear', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_Alec_second_tryDec7\\\\Alec_second_try_Devon95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\SchwartzLab\\\\anaconda3\\\\envs\\\\bahavior_rig_\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\DLC\\\\Alec_second_try-Devon-2020-12-07\\\\dlc-models\\\\iteration-0\\\\Alec_second_tryDec7-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07/evaluation-results/  already exists!\n",
      "Running  DLC_resnet50_Alec_second_tryDec7shuffle1_200000  with # of trainingiterations: 200000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548it [01:05,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-200000\n",
      "Results for 200000  training iterations: 95 1 train error: 2.06 pixels. Test error: 3.06  pixels.\n",
      "With pcutoff of 0.8  train error: 2.06 pixels. Test error: 3.0 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07/evaluation-results/  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\evaluation-results\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1  already exists!\n",
      "Initializing ResNet\n",
      "Activating extracting of PAFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.61it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_save_all_maps(config_path, shuffle=[1], Indices=[0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\evaluation-results\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1  already exists!\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\evaluation-results\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\\DLC_resnet50_Alec_third_try_maDec7shuffle1_60000-snapshot-60000.h5\n",
      "Computing distances...\n",
      "rpck 0.3437776561760351 rpck train: 0.38245850952950045\n",
      "rmse 2.935899701267398 miss 1.1428571428571428 hit 2.7142857142857144\n",
      "rpck 0.3941589434497399 rpck train: 0.4889525898421739\n",
      "rmse 3.268894649330012 miss 0.4268292682926829 hit 3.3292682926829267\n",
      "rpck 0.3873050938305962 rpck train: 0.41929885470917666\n",
      "rmse 2.9635732647900346 miss 0.88 hit 3.04\n",
      "rpck 0.2718412536140126 rpck train: 0.2577514813513199\n",
      "rmse 2.547676153854701 miss 2.5714285714285716 hit 2.0\n",
      "rpck 0.3879505909155049 rpck train: 0.48751729393696097\n",
      "rmse 3.2752997709507077 miss 0.4444444444444444 hit 3.3209876543209877\n",
      "rpck 0.3412914687452403 rpck train: 0.4007347025542752\n",
      "rmse 3.052033617714577 miss 1.2419354838709677 hit 2.838709677419355\n",
      "rpck 0.3088927074949706 rpck train: 0.35151768719336546\n",
      "rmse 2.925865703645167 miss 1.7037037037037037 hit 2.462962962962963\n",
      "rpck 0.383263136109458 rpck train: 0.46926920269553496\n",
      "rmse 3.2842722833295683 miss 0.6351351351351351 hit 3.2972972972972974\n",
      "rpck 0.3984355126987286 rpck train: 0.5062937577515452\n",
      "rmse 3.259571561020499 miss 0.47761194029850745 hit 3.537313432835821\n",
      "rpck 0.40477967981372287 rpck train: 0.4893071490937212\n",
      "rmse 3.241710881987502 miss 0.3855421686746988 hit 3.3493975903614457\n",
      "rpck 0.39580190141975863 rpck train: 0.489601323969555\n",
      "rmse 3.277959487838631 miss 0.3950617283950617 hit 3.3703703703703702\n",
      "rpck 0.31112411743183405 rpck train: 0.3867925264120381\n",
      "rmse 2.7004319970478257 miss 1.6 hit 2.6\n",
      "rpck 0.28498792356100416 rpck train: 0.31894922451189306\n",
      "rmse 2.831359833344778 miss 2.0238095238095237 hit 2.2857142857142856\n",
      "rpck 0.3582238662939443 rpck train: 0.41769491119927354\n",
      "rmse 3.0320487101553124 miss 1.126984126984127 hit 2.9523809523809526\n",
      "rpck 0.3928461876175099 rpck train: 0.500645725228056\n",
      "rmse 3.2532506735861513 miss 0.5303030303030303 hit 3.515151515151515\n",
      "rpck 0.34623897987700675 rpck train: 0.40305087806951523\n",
      "rmse 3.054440386007816 miss 1.2096774193548387 hit 2.870967741935484\n",
      "rpck 0.2718412536140126 rpck train: 0.2577514813513199\n",
      "rmse 2.547676153854701 miss 2.5714285714285716 hit 2.0\n",
      "rpck 0.3596493709804227 rpck train: 0.44414267685031555\n",
      "rmse 3.0268111154383583 miss 0.0 hit 2.0\n",
      "rpck 0.39944055542234636 rpck train: 0.5081445534954773\n",
      "rmse 3.2542717270463157 miss 0.4492753623188406 hit 3.4782608695652173\n",
      "rpck 0.3875459653235051 rpck train: 0.4775406859312274\n",
      "rmse 3.279867186553286 miss 0.5733333333333334 hit 3.32\n",
      "rpck 0.4163917477292522 rpck train: 0.5077094365952778\n",
      "rmse 3.1920037106621915 miss 0.3972602739726027 hit 3.4657534246575343\n",
      "rpck 0.404935165878465 rpck train: 0.49005287491851673\n",
      "rmse 3.2588632150391685 miss 0.32558139534883723 hit 3.3372093023255816\n",
      "rpck 0.39751752203680046 rpck train: 0.5084177505105176\n",
      "rmse 3.262012528655606 miss 0.43478260869565216 hit 3.5072463768115942\n",
      "rpck 0.41276315183469703 rpck train: 0.4905926662886118\n",
      "rmse 3.240920277271228 miss 0.3333333333333333 hit 3.380952380952381\n",
      "rpck 0.41733684320687187 rpck train: 0.50585623739561\n",
      "rmse 3.270184369090887 miss 0.27380952380952384 hit 3.380952380952381\n",
      "rpck 0.40409658032858675 rpck train: 0.4914124695936941\n",
      "rmse 3.7762316976753847 miss 0.2988505747126437 hit 3.3333333333333335\n",
      "rpck 0.41733684320687187 rpck train: 0.50585623739561\n",
      "rmse 3.270184369090887 miss 0.27380952380952384 hit 3.380952380952381\n",
      "rpck 0.39751752203680046 rpck train: 0.5084177505105176\n",
      "rmse 3.262012528655606 miss 0.43478260869565216 hit 3.5072463768115942\n",
      "rpck 0.4163917477292522 rpck train: 0.5077088019183317\n",
      "rmse 3.1920037106621915 miss 0.3972602739726027 hit 3.4657534246575343\n",
      "rpck 0.4160805154416483 rpck train: 0.4922323860353046\n",
      "rmse 3.761063933126671 miss 0.23863636363636365 hit 3.3636363636363638\n",
      "rpck 0.40403744666262337 rpck train: 0.5076305661547657\n",
      "rmse 3.247926495363895 miss 0.42857142857142855 hit 3.4857142857142858\n",
      "rpck 0.36180320088695034 rpck train: 0.4352585929912752\n",
      "rmse 3.117009582697069 miss 1.105263157894737 hit 3.1842105263157894\n",
      "rpck 0.34849160302525145 rpck train: 0.41257151217254373\n",
      "rmse 3.0328158814779504 miss 1.2063492063492063 hit 2.873015873015873\n",
      "rpck 0.3784211001100862 rpck train: 0.4493471628537594\n",
      "rmse 3.216426892613829 miss 0.7794117647058824 hit 3.2058823529411766\n",
      "rpck 0.4088341704089664 rpck train: 0.508138506299756\n",
      "rmse 3.2118335767313337 miss 0.4225352112676056 hit 3.464788732394366\n",
      "rpck 0.41688415670574147 rpck train: 0.5074058726684384\n",
      "rmse 3.198445864384254 miss 0.3888888888888889 hit 3.486111111111111\n",
      "rpck 0.40551220109162794 rpck train: 0.48885405180950736\n",
      "rmse 3.2223315668660555 miss 0.41025641025641024 hit 3.448717948717949\n",
      "rpck 0.2588340400326696 rpck train: 0.2796790101568863\n",
      "rmse 2.757660228209293 miss 2.125 hit 2.0\n",
      "rpck 0.4041859033345097 rpck train: 0.48968872385411655\n",
      "rmse 3.2239698306631754 miss 0.39285714285714285 hit 3.3214285714285716\n",
      "rpck 0.40551220109162794 rpck train: 0.48885405180950736\n",
      "rmse 3.2223315668660555 miss 0.41025641025641024 hit 3.448717948717949\n",
      "rpck 0.4160805154416483 rpck train: 0.4922323860353046\n",
      "rmse 3.761063933126671 miss 0.23863636363636365 hit 3.3636363636363638\n",
      "rpck 0.2671779814025363 rpck train: 0.27049712160774947\n",
      "rmse 2.7421901419136985 miss 2.3 hit 2.0\n",
      "rpck 0.30797974593512506 rpck train: 0.4403569973833484\n",
      "rmse 2.9293428670720068 miss 1.3333333333333333 hit 2.6666666666666665\n",
      "rpck 0.41220471863212405 rpck train: 0.49053717124543017\n",
      "rmse 3.233345347911844 miss 0.34523809523809523 hit 3.369047619047619\n",
      "rpck 0.4088341704089664 rpck train: 0.5084340629729419\n",
      "rmse 3.2118335767313337 miss 0.4225352112676056 hit 3.464788732394366\n",
      "rpck 0.40551220109162794 rpck train: 0.48885405180950736\n",
      "rmse 3.2223315668660555 miss 0.41025641025641024 hit 3.448717948717949\n",
      "rpck 0.3926982370450806 rpck train: 0.5073142864042218\n",
      "rmse 3.354607480679348 miss 0.3918918918918919 hit 3.418918918918919\n",
      "rpck 0.4170326051699638 rpck train: 0.5086006621353465\n",
      "rmse 3.2400367615583474 miss 0.2976190476190476 hit 3.357142857142857\n",
      "rpck 0.4088341704089664 rpck train: 0.508364207176377\n",
      "rmse 3.2118335767313337 miss 0.4225352112676056 hit 3.464788732394366\n",
      "rpck 0.34849160302525145 rpck train: 0.41250446615892783\n",
      "rmse 3.0328158814779504 miss 1.2063492063492063 hit 2.873015873015873\n",
      "rpck 0.4104514002472245 rpck train: 0.5076021528077348\n",
      "rmse 3.253361810001655 miss 0.43243243243243246 hit 3.445945945945946\n",
      "rpck 0.4018696077101766 rpck train: 0.5090078342776704\n",
      "rmse 3.249729000729155 miss 0.4393939393939394 hit 3.590909090909091\n",
      "rpck 0.4002325674931466 rpck train: 0.5064355983544956\n",
      "rmse 3.3058102128614806 miss 0.4647887323943662 hit 3.464788732394366\n",
      "rpck 0.4018696077101766 rpck train: 0.5090078342776704\n",
      "rmse 3.249729000729155 miss 0.4393939393939394 hit 3.590909090909091\n",
      "rpck 0.4029374174816527 rpck train: 0.5081811637526881\n",
      "rmse 3.2271894119199978 miss 0.4411764705882353 hit 3.5441176470588234\n",
      "rpck 0.4029374174816527 rpck train: 0.5081811637526881\n",
      "rmse 3.2271894119199978 miss 0.4411764705882353 hit 3.5441176470588234\n",
      "rpck 0.40872441141889965 rpck train: 0.5077588123442667\n",
      "rmse 3.229014383948934 miss 0.4084507042253521 hit 3.492957746478873\n",
      "rpck 0.30797974593512506 rpck train: 0.4562046171779656\n",
      "rmse 2.9293428670720068 miss 1.3333333333333333 hit 2.6666666666666665\n",
      "rpck 0.39562825225330556 rpck train: 0.48929296409710066\n",
      "rmse 3.2560962653021104 miss 0.42168674698795183 hit 3.3132530120481927\n",
      "rpck 0.39846582558919774 rpck train: 0.48972518907173185\n",
      "rmse 3.271750339437227 miss 0.38271604938271603 hit 3.382716049382716\n",
      "rpck 0.4029374174816527 rpck train: 0.5081811637526881\n",
      "rmse 3.2271894119199978 miss 0.4411764705882353 hit 3.5441176470588234\n",
      "rpck 0.39321132492280786 rpck train: 0.4858674977696339\n",
      "rmse 3.2836985399621845 miss 0.44871794871794873 hit 3.358974358974359\n",
      "rpck 0.40527764323851456 rpck train: 0.5080588221023965\n",
      "rmse 3.3038207109600584 miss 0.31645569620253167 hit 3.430379746835443\n",
      "rpck 0.4029374174816527 rpck train: 0.5081890895952426\n",
      "rmse 3.2271894119199978 miss 0.4411764705882353 hit 3.5441176470588234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpck 0.3980286840732452 rpck train: 0.4891176902555689\n",
      "rmse 3.2580202533299274 miss 0.3950617283950617 hit 3.3703703703703702\n",
      "rpck 0.28267479286098623 rpck train: 0.29680733701372825\n",
      "rmse 2.720833936279059 miss 2.121212121212121 hit 2.1515151515151514\n",
      "rpck 0.39249646368584523 rpck train: 0.49988921593997315\n",
      "rmse 3.222678556484402 miss 0.6031746031746031 hit 3.4761904761904763\n",
      "rpck 0.3913527414712689 rpck train: 0.5003116124315573\n",
      "rmse 3.266974818318141 miss 0.5074626865671642 hit 3.4925373134328357\n",
      "rpck 0.4101943678141665 rpck train: 0.49075287340729024\n",
      "rmse 3.246907670372581 miss 0.34523809523809523 hit 3.369047619047619\n",
      "rpck 0.41259769493762893 rpck train: 0.5074580868018019\n",
      "rmse 3.203915446850555 miss 0.4084507042253521 hit 3.4788732394366195\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\evaluation-results\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\\DLC_resnet50_Alec_third_try_maDec7shuffle1_60000-snapshot-60000.h5\n",
      "Saving optimal inference parameters...\n",
      "   train_iter  train_frac  shuffle  rmse_train  hits_train  misses_train  falsepos_train  ndetects_train  pck_train  rpck_train  rmse_test  hits_test  misses_test  falsepos_test  ndetects_test  pck_test  rpck_test\n",
      "0     60000.0        95.0      1.0     2.72595    3.942495      0.193957        0.002924        1.060429   0.926342    0.832173   3.249729   3.590909     0.439394       0.151515       1.015152  0.822421    0.74855\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_multianimal_crossvalidate(config_path, Shuffles=[1], edgewisecondition=True, leastbpts=1, init_points=20, n_iter=50, target='rpck_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 6 anaylze novel videos\n",
    "\n",
    "### path of all novel videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-02_Test1male_A\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-02_TestFemale1_C\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-02_TestFemale2_C\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-02_TestMale2_B\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-02_TestMale3_C\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_Male2TestExtendedExplorationTime(1)\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_TestFemale_Female1_B\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_TestFemale_Female2_C\\\\camera_17391304.MOV', 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_TestFemale_Male1_A\\\\camera_17391304.MOV']\n"
     ]
    }
   ],
   "source": [
    "novel_video1 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\camera_17391304.MOV'\n",
    "novel_video2 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\camera_17391304.MOV'\n",
    "novel_video3 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\camera_17391304.MOV'\n",
    "novel_video4 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male2\\camera_17391304.MOV'\n",
    "novel_video5 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male3\\camera_17391304.MOV'\n",
    "novel_video6 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male4\\camera_17391304.MOV'\n",
    "novel_video7 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\camera_17391304.MOV'\n",
    "novel_video8 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-11-19_MomReunite\\camera_17391304.MOV'\n",
    "novel_video9 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Male2TestExtendedExplorationTime(1)\\camera_17391304.MOV'\n",
    "novel_videos=[novel_video1,novel_video2,novel_video3,novel_video4,novel_video5,novel_video6,novel_video7,novel_video8,novel_video9]\n",
    "#novel_videos = [novel_video8, novel_video9]\n",
    "\n",
    "import os\n",
    "novel_video_path = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos'\n",
    "video_list = os.listdir(novel_video_path)\n",
    "novel_videos=[novel_video_path+ '\\\\'+video+'\\\\camera_17391304.MOV' for video in video_list]\n",
    "print(novel_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-186000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_second_try-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_second_tryDec7-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7831 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_Test1male_A\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_Test1male_A  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_Test1male_A\\camera_17391304.MOV\n",
      "Duration of video [s]:  313.24 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7831  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7878it [10:34, 12.15it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7878it [10:37, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_Test1male_A...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7638 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale1_C\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale1_C  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale1_C\\camera_17391304.MOV\n",
      "Duration of video [s]:  305.52 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7638  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:18, 12.13it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:21, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale1_C...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale2_C\\camera_17391304.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale2_C  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale2_C\\camera_17391304.MOV\n",
      "Duration of video [s]:  306.16 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7654  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:22, 12.16it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:27, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestFemale2_C...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale2_B\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale2_B  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale2_B\\camera_17391304.MOV\n",
      "Duration of video [s]: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7486 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 299.44 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7486  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7548it [10:09, 12.11it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7548it [10:11, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale2_B...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7683 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale3_C\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale3_C  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale3_C\\camera_17391304.MOV\n",
      "Duration of video [s]:  307.32 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7683  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7752it [10:29, 12.41it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7752it [10:30, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-02_TestMale3_C...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Male2TestExtendedExplorationTime(1)\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Male2TestExtendedExplorationTime(1)  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Male2TestExtendedExplorationTime(1)\\camera_17391304.MOV\n",
      "Duration of video [s]:  1874.88 , recorded with  25.0 fps!\n",
      "Overall # of frames:  46872  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47268it [1:04:12, 12.27it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  46872\n",
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Male2TestExtendedExplorationTime(1)...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7644 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female1_B\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female1_B  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female1_B\\camera_17391304.MOV\n",
      "Duration of video [s]:  305.76 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7644  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:26, 12.03it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7676it [10:30, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female1_B...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female2_C\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female2_C  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female2_C\\camera_17391304.MOV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7569 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  302.76 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7569  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7575it [10:16, 12.28it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7575it [10:22, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Female2_C...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male1_A\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male1_A  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male1_A\\camera_17391304.MOV\n",
      "Duration of video [s]: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 334.96 , recorded with  25.0 fps!\n",
      "Overall # of frames:  8374  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8383it [11:19, 11.84it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8383it [11:26, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male1_A...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_Alec_second_tryDec7shuffle1_186000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path,\n",
    "                          novel_videos,\n",
    "                          save_as_csv=True,\n",
    "                          videotype='mov',\n",
    "                         shuffle=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maDLC: detect tracklets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7746it [00:24, 311.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:00, 202.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7939it [00:24, 318.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [00:00, 1167.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46224it [00:53, 866.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male2\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male2  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:00, 786.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male2\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8166it [00:14, 582.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male3\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male3  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:00, 702.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male3\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7856it [00:14, 547.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male4\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male4  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 804.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male4\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7995it [00:17, 466.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "Processing...  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\camera_17391304.MOV\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:00, 1031.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44693it [00:52, 847.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tracklets were created. Now you can 'refine_tracklets'.\n",
      "Using snapshot-60000 for model C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\DLC\\Alec_third_try_ma-Devon-2020-12-07\\dlc-models\\iteration-0\\Alec_third_try_maDec7-trainset95shuffle1\n",
      "No video(s) found. Please check your path!\n"
     ]
    }
   ],
   "source": [
    "for video in novel_videos:\n",
    "    deeplabcut.convert_detections2tracklets(config_path, \n",
    "                                            video, \n",
    "                                            videotype='mov', \n",
    "                                            shuffle=1, \n",
    "                                            #trainingsetindex=0, \n",
    "                                            track_method='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_video1 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video2 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video3 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video4 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male2\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video5 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male3\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video6 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_TestFemale_Male4\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video7 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "novel_video8 = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-11-09_MomReunite\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_bx.pickle'\n",
    "pickle_files=[novel_video1,novel_video2,novel_video3,novel_video4,novel_video5,novel_video6,novel_video7,novel_video8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:00<00:00, 1984.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.refine_tracklets(config_path, pickle_files[0], novel_videos[0], min_swap_len=2, min_tracklet_len=2, trail_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 452.09it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_1yF2M_Male2\\\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_sk.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-27d7c0d9e62f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickle_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_raw_tracks_to_h5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\tracklets.py\u001b[0m in \u001b[0;36mconvert_raw_tracks_to_h5\u001b[1;34m(config, tracks_pickle, output_name, min_tracklet_len, max_gap)\u001b[0m\n\u001b[0;32m   1157\u001b[0m ):\n\u001b[0;32m   1158\u001b[0m     \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrackletManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_tracklet_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_gap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m     \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_tracklets_from_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracks_pickle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m     \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bahavior_rig_\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\tracklets.py\u001b[0m in \u001b[0;36mload_tracklets_from_pickle\u001b[1;34m(self, filename, auto_fill)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_tracklets_from_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m             \u001b[0mtracklets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_tracklets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracklets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_fill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\SchwartzLab\\\\PycharmProjects\\\\bahavior_rig\\\\multimedia\\\\videos\\\\2020-12-04_1yF2M_Male2\\\\camera_17391304DLC_resnet50_Alec_third_try_maDec7shuffle1_60000_sk.pickle'"
     ]
    }
   ],
   "source": [
    "for item in pickle_files:\n",
    "    deeplabcut.convert_raw_tracks_to_h5(config_path, pickle_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\camera_17391304.MOV and data.\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male1\\plot-poses\\camera_17391304  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\camera_17391304.MOV and data.\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_1yF2M_Male2\\plot-poses\\camera_17391304  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\camera_17391304.MOV and data.\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_Female1TestExtendedExplorationTime\\plot-poses\\camera_17391304  already exists!\n",
      "Loading  C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\camera_17391304.MOV and data.\n",
      "C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\multimedia\\videos\\2020-12-04_MaleExploringExtendedTime\\plot-poses\\camera_17391304  already exists!\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.plot_trajectories(config_path, novel_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(config_path,novel_videos,save_frames=False,trailpoints=5,videotype='mov',draw_skeleton='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.export_model(config_path,shuffle=1,\n",
    "                        TFGPUinference=False,\n",
    "                        make_tar=False)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
