{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59adbe04-9618-4ce1-ade0-68a0cc191aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import toml\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, IntSlider, IntText\n",
    "from IPython.display import Image\n",
    "from utils.calibration_utils import Calib\n",
    "from tqdm import trange, tqdm\n",
    "# from multiprocess import Pool\n",
    "# from numba import jit\n",
    "# import numba\n",
    "# from scipy.interpolate import interp2d as interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baecc134-ca5b-4389-ad0d-139767792128",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Calib('extrinsic').board\n",
    "board_dict = board.dictionary\n",
    "params = cv2.aruco.DetectorParameters_create()\n",
    "# params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_CONTOUR\n",
    "# params.adaptiveThreshWinSizeMin = 3\n",
    "# params.adaptiveThreshWinSizeMax = 103\n",
    "# params.adaptiveThreshWinSizeStep = 4\n",
    "# params.adaptiveThreshConstant = 2\n",
    "# params.detectInvertedMarker = True\n",
    "params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_CONTOUR\n",
    "params.adaptiveThreshWinSizeMin = 100\n",
    "params.adaptiveThreshWinSizeMax = 600\n",
    "params.adaptiveThreshWinSizeStep = 50\n",
    "params.adaptiveThreshConstant = 5\n",
    "\n",
    "MIN_MARKERS = 2\n",
    "\n",
    "def get_corners(frame, camera_mat, dist_coeff):\n",
    "#     valid = False\n",
    "#     print(frame.shape, camera_mat.shape, dist_coeff.shape)\n",
    "    markerCorners,markerIds,rejectedCorners = cv2.aruco.detectMarkers(frame, board_dict, parameters=params)\n",
    "    markerCorners,markerIds, rejectedCorners,_ = cv2.aruco.refineDetectedMarkers(\n",
    "        frame, board, markerCorners, markerIds,rejectedCorners,\n",
    "        camera_mat, dist_coeff,\n",
    "        parameters=params)\n",
    "    markerCorners = np.array(markerCorners)\n",
    "    rejectedCorners = np.array(rejectedCorners)\n",
    "    \n",
    "    if len(markerCorners):\n",
    "        #get the checkboard corners\n",
    "        _, checkerCorners, checkerIds = cv2.aruco.interpolateCornersCharuco(\n",
    "            markerCorners, markerIds, frame, board, np.array([]), np.array([]), camera_mat, dist_coeff, MIN_MARKERS)\n",
    "        \n",
    "        if checkerCorners is None:\n",
    "            checkerCorners = []\n",
    "    else:\n",
    "        checkerCorners = []\n",
    "        checkerIds = []\n",
    "    \n",
    "    return markerCorners, checkerCorners, rejectedCorners, markerIds, checkerIds\n",
    "\n",
    "def undistort_image(frame, camera_mat, dist_coeff):\n",
    "    if len(dist_coeff) == 4:\n",
    "        #case fisheye\n",
    "        K = camera_mat.copy()\n",
    "        K[2,2] = 1.0\n",
    "        im_shape = (frame.shape[1], frame.shape[0])\n",
    "        newK = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(K, dist_coeff, im_shape, np.eye(3), balance = 1.0)\n",
    "        m1,m2 = cv2.fisheye.initUndistortRectifyMap(camera_mat, dist_coeff, np.eye(3), newK, im_shape, cv2.CV_32FC1)\n",
    "        \n",
    "        return cv2.remap(frame, m1,m2,interpolation = cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT),m1,m2\n",
    "    else:\n",
    "        return cv2.undistort(frame, camera_mat, dist_coeff),camera_mat,dist_coeff\n",
    "    \n",
    "def undistort_points(pts, m1, m2):\n",
    "#     if type(m2) != np.ndarray:\n",
    "    if len(m2) != 14:\n",
    "        #case fisheye\n",
    "        pts = pts.reshape((-1,2))\n",
    "        pts_out = pts.copy()\n",
    "        \n",
    "#         i = pts[:,0].astype(int)*pts.shape[1] + pts[:,1].astype(int)\n",
    "        i = pts[:,1].astype(int)*pts.shape[0] + pts[:,0].astype(int)\n",
    "        \n",
    "        pts_out[:,0] = m1.flatten()[i]\n",
    "        pts_out[:,1] = m2.flatten()[i]\n",
    "        return pts_out.reshape((-1,1,2))\n",
    "    else:\n",
    "#         print(m1.shape, m2.shape)\n",
    "        return cv2.undistortPoints(np.ascontiguousarray(pts.reshape((-1,1,2))), m1, m2)\n",
    "\n",
    "def draw_corners(frame,camera_mat, dist_coeff):\n",
    "    markerCorners,checkerCorners,rejectedCorners,markerIds,checkerIds = get_corners(frame, camera_mat, dist_coeff)\n",
    "    \n",
    "    #frame,m1,m2 = undistort_image(frame, camera_mat, dist_coeff)\n",
    "    \n",
    "    if len(checkerCorners):\n",
    "        #draw the checkerboard corners\n",
    "        #frame = cv2.aruco.drawDetectedCornersCharuco(frame, undistort_points(checkerCorners,m1,m2), cornerColor = (0,255,0))\n",
    "        frame = cv2.aruco.drawDetectedCornersCharuco(frame, checkerCorners, cornerColor = (0,255,0))\n",
    "    \n",
    "    #draw the rejected corners\n",
    "    #frame = cv2.aruco.drawDetectedCornersCharuco(frame, undistort_points(rejectedCorners,m1,m2), cornerColor = (255,0,0))\n",
    "    frame = cv2.aruco.drawDetectedCornersCharuco(frame, rejectedCorners, cornerColor = (255,0,0))\n",
    "    \n",
    "    #draw the qr code markers\n",
    "    if len(markerCorners):\n",
    "        #frame = cv2.aruco.drawDetectedMarkers(frame, np.array(undistort_points(markerCorners, m1,m2)).reshape(-1,4,1,2), markerIds, borderColor = (0,255,255))\n",
    "        frame = cv2.aruco.drawDetectedMarkers(frame, np.array(markerCorners).reshape(-1,4,1,2), markerIds, borderColor = (0,255,255))\n",
    "        \n",
    "    return frame, checkerCorners, checkerIds\n",
    "\n",
    "\n",
    "def estimate_pose(markerCorners,ids,camera_mat,dist_coeff):\n",
    "#     if not len(markerCorners):\n",
    "#         return False,None,None\n",
    "    \n",
    "#     ret, detectedCorners, detectedIds = cv2.aruco.interpolateCornersCharuco(\n",
    "# \t# \t\tdetectedCorners, detectedIds, gray, board)\n",
    "    \n",
    "#     undistorted = undistort_points(markerCorners, camera_mat, dist_coeff)\n",
    "#     cm = np.eye(3)\n",
    "#     dc = np.zeros((5))\n",
    "    rvec = np.empty((3,1))\n",
    "    tvec = np.empty((3,1))\n",
    "#     return cv2.aruco.estimatePoseCharucoBoard(undistorted,ids,board,cameraMatrix=cm,distCoeffs=dc,rvec=rvec,tvec=tvec,useExtrinsicGuess=False)\n",
    "    return cv2.aruco.estimatePoseCharucoBoard(markerCorners,ids,board,cameraMatrix=camera_mat,distCoeffs=dist_coeff,rvec=rvec,tvec=tvec,useExtrinsicGuess=False)\n",
    "    \n",
    "def xyz_to_xy(xyz, extrinsic, intrinsic):\n",
    "    rvec, _ = cv2.Rodrigues(extrinsic[0:3, 0:3])\n",
    "    tvec = extrinsic[0:3, 3]\n",
    "    if len(intrinsic['dist_coeff']) == 4:\n",
    "        #case fisheye\n",
    "#         xyz = xyz[:, np.newaxis, :]\n",
    "        xy, _ = cv2.fisheye.projectPoints(xyz, rvec, tvec, intrinsic['camera_mat'], intrinsic['dist_coeff'])\n",
    "    else:\n",
    "        #case normal camera\n",
    "        xy, _ = cv2.projectPoints(xyz, rvec, tvec, intrinsic['camera_mat'], intrinsic['dist_coeff'])\n",
    "        \n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88c2d78-9e31-4d04-9249-4c2dff07963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_figure(vid, intrinsics, idx=0):\n",
    "    \n",
    "    frame_counts = [c.get(cv2.CAP_PROP_FRAME_COUNT) for c in vid]\n",
    "    plt.close('all')\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    with output:\n",
    "        fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(10,7)) #TODO: 2*2 = 4\n",
    "    \n",
    "    markers_count = [IntText(value=0, description=f'camera {i}', disabled=True) for i in range(len(vid))]\n",
    "    is_valid = [widgets.Valid(value=False, readout='Pose not estimated') for i in range(len(vid))]\n",
    "    \n",
    "    axs = axs.flatten()\n",
    "    ims = [axs[i].imshow(np.array(vid[i].read()[1]).astype(float)) for i in range(len(vid))]\n",
    "    \n",
    "    class Intrinsics():\n",
    "        def __init__(self):\n",
    "            self.cm_children = []\n",
    "            self.dc_children = []\n",
    "            self.reset_intrinsics()\n",
    "            \n",
    "        def reset_intrinsics(self):\n",
    "            self.camera_mats = [i['camera_mat'].copy() for i in intrinsics]\n",
    "            self.dist_coeffs = [i['dist_coeff'].copy() for i in intrinsics]\n",
    "            for c,(i,j,k) in self.cm_children:\n",
    "                c.value = self.camera_mats[i][j,k]\n",
    "            for c,(i,j) in self.dc_children:\n",
    "                c.value = self.dist_coeffs[i][j,k]\n",
    "            \n",
    "        def register_cm(self, child, i,j,k):\n",
    "            self.cm_children.append((child,(i,j,k)))\n",
    "            \n",
    "        def register_dc(self, child, i,j):\n",
    "            self.dc_children.append((child,(i,j)))\n",
    "            \n",
    "        def set_cm(self,i,j,k,x):\n",
    "            self.camera_mats[i][j,k] = x\n",
    "            \n",
    "        def set_dc(self,i,j,x):\n",
    "            print('changing dc')\n",
    "            self.dist_coeffs[i][j] = x\n",
    "        \n",
    "    intrinsic = Intrinsics()\n",
    "     \n",
    "    def update_frame(idx):\n",
    "#         print('redrawing')\n",
    "        for i in range(len(vid)):\n",
    "            vid[i].set(1, idx)\n",
    "            _,frame = vid[i].read()\n",
    "            frame, corners, ids= draw_corners(frame,intrinsic.camera_mats[i],intrinsic.dist_coeffs[i])\n",
    "            ims[i].set_data(frame)\n",
    "            markers_count[i].value = len(corners)\n",
    "            if len(corners)>3 and any(ids%2) and not all(ids%2):\n",
    "                is_valid[i].value,_,_ = estimate_pose(corners,ids,intrinsic.camera_mats[i],intrinsic.dist_coeffs[i])\n",
    "            else: is_valid[i].value = False\n",
    "    \n",
    "    update_frame(idx)\n",
    "    \n",
    "    def respond_to_slider(change):\n",
    "        if change['name']=='value':\n",
    "            update_frame(change['new'])\n",
    "    \n",
    "    slider = IntSlider(step=1, value=idx, min=0, max=min(frame_counts),description='Frame index')\n",
    "    slider.observe(respond_to_slider)\n",
    "    \n",
    "    def update_param(change):\n",
    "        if change['name'] == 'value':\n",
    "            setattr(params, change['owner'].description, change['new'])\n",
    "            update_frame(vid[0].get(1) - 1)\n",
    "            \n",
    "    param_controls = []\n",
    "    for x in dir(params):\n",
    "        if x.startswith('__') or x=='create': continue\n",
    "        a = getattr(params,x)\n",
    "        if type(a) == int:\n",
    "            w = widgets.IntText\n",
    "        elif type(a) == float:\n",
    "            w = widgets.FloatText\n",
    "        elif type(a) == bool:\n",
    "            w = widgets.ToggleButton\n",
    "        else:\n",
    "            raise 'Bad value!'\n",
    "        param_controls.append(\n",
    "            w(value = getattr(params,x), description = x, style={'description_width':'initial'})\n",
    "        )\n",
    "        param_controls[-1].observe(update_param)\n",
    "        \n",
    "    def set_min_markers(change):\n",
    "        if change['name']=='value':\n",
    "            MIN_MARKERS = change['new']\n",
    "            update_frame(vid[0].get(1) - 1)\n",
    "            \n",
    "    param_controls.append(IntText(value = MIN_MARKERS, description = 'minMarkersForInterpolation', min=1, max=4, style={'description_width':'initial'}))\n",
    "    param_controls[-1].observe(set_min_markers)\n",
    "    \n",
    "    reset_button = widgets.Button(description='Reset intrinsics', icon='reset')\n",
    "    reset_button.on_click(lambda x: intrinsic.reset_intrinsics())\n",
    "    reset_button.on_click(lambda x: update_frame(vid[0].get(1) - 1))\n",
    "    \n",
    "    def observe_cm(i,j,k,change):\n",
    "        if change['name']=='value':\n",
    "            intrinsic.set_cm(i,j,k,change['new'])\n",
    "            update_frame(vid[0].get(1) - 1)\n",
    "    def observe_dc(i,j,change):\n",
    "        if change['name']=='value':\n",
    "            intrinsic.set_dc(i,j,change['new'])\n",
    "            update_frame(vid[0].get(1) - 1)\n",
    "            \n",
    "                             \n",
    "    cm_text = [[[widgets.FloatText(value=ccc, layout=widgets.Layout(width = '90px')) for ccc in cc] for cc in c] for c in intrinsic.camera_mats]\n",
    "    for i,c in enumerate(cm_text):\n",
    "        for j,cc in enumerate(c):\n",
    "            for k,ccc in enumerate(cc):\n",
    "                ccc.observe(lambda change: observe_cm(i,j,k,change))\n",
    "                intrinsic.register_cm(ccc,i,j,k)\n",
    "    \n",
    "                \n",
    "    dc_text = [[widgets.FloatText(value=d[dd], layout=widgets.Layout(width = '70px')) for dd in range(4)] for d in intrinsic.dist_coeffs]\n",
    "    for i,d in enumerate(dc_text):\n",
    "        for j,dd in enumerate(d):\n",
    "            dd.observe(lambda change: observe_dc(i,j,change))\n",
    "            intrinsic.register_dc(dd,i,j)\n",
    "            \n",
    "    int_text = [\n",
    "        VBox([\n",
    "            *[HBox(w) for w in cm_text[i]],\n",
    "            HBox(dc_text[i])\n",
    "        ])\n",
    "        for i in range(len(intrinsic.camera_mats))]\n",
    "    \n",
    "    \n",
    "    display(VBox([HBox([\n",
    "        VBox([slider,reset_button]),\n",
    "        VBox([\n",
    "            widgets.Label('Checker detection', layout=widgets.Layout(display='flex',justify_content='center')),\n",
    "            HBox([VBox([valid,marker]) for marker,valid in zip(markers_count,is_valid)]),\n",
    "            HBox(int_text, layout=widgets.Layout(display='flex',justify_content='space-around'))\n",
    "#             cm_text[0]\n",
    "        ])\n",
    "    ]),HBox([VBox(param_controls),output])]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b869daaf-9997-42c8-82eb-9aee241edbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1854.0, 1884.0, 1926.0, 1905.0]\n"
     ]
    }
   ],
   "source": [
    "vid = [cv2.VideoCapture(i) for i in [\n",
    "    'config/config_extrinsic_17391304.MOV',\n",
    "    'config/config_extrinsic_17391290.MOV',\n",
    "    'config/config_extrinsic_19412282.MOV',\n",
    "    'config/config_extrinsic_21340171.MOV'\n",
    "]]\n",
    "print([v.get(cv2.CAP_PROP_FRAME_COUNT) for v in vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e278cfee-4a5f-4cd2-95d2-04000a248c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = [toml.load(path) for path in [\n",
    "    'config/config_intrinsic_17391304.toml',\n",
    "    'config/config_intrinsic_17391290.toml',\n",
    "    'config/config_intrinsic_19412282.toml',\n",
    "    'config/config_intrinsic_21340171.toml',\n",
    "]]\n",
    "for i in range(len(intrinsics)):\n",
    "    intrinsics[i]['camera_mat'] = np.array(intrinsics[i]['camera_mat'])\n",
    "    intrinsics[i]['dist_coeff'] = np.array(intrinsics[i]['dist_coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3606dca-b2d8-4001-b984-c3da04a2f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cb1f1014aa4300841a3d728b82397f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(IntSlider(value=324, description='Frame index', max=1854), Button…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(intrinsics[0]['camera_mat'].shape)\n",
    "draw_figure(vid, intrinsics, idx=324)#2541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccddfaa6-ebe4-4c7e-b539-23ba67cc73dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c4ea1029934e7ba7bbcd2fcc12442c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SchwartzLab\\anaconda3\\envs\\behavior_rig\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:682: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x = np.array(x, subok=True, copy=copy)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5e62f2ec79d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mundistort_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintrinsics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'camera_mat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintrinsics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dist_coeff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m#     axs[i].scatter(pts[:,0],pts[:,1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\behavior_rig\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    701\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m    702\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[1;32m--> 703\u001b[1;33m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    }
   ],
   "source": [
    "# idx = 2334#939#2334\n",
    "# match = (0,3)\n",
    "idx = 324\n",
    "match = (0,3)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fig,axs = plt.subplots(nrows=2,ncols=2,figsize=(15,10)) #TODO: 2*2 = 4\n",
    "axs = axs.flatten()\n",
    "ims = []        \n",
    "\n",
    "for i in range(len(vid)):\n",
    "    vid[i].set(1, idx)\n",
    "    frame = cv2.cvtColor(vid[i].read()[1],cv2.COLOR_BGR2GRAY)\n",
    "    #     frame = undistort_image(frame,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff'])[0]\n",
    "    \n",
    "    ims.append(axs[i].imshow(frame, cmap='gray'))\n",
    "    \n",
    "\n",
    "for i in match:\n",
    "    vid[i].set(1, idx)\n",
    "    _,frame = vid[i].read()\n",
    "    _, corners, _, _, ids = get_corners(frame,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff'])\n",
    "    \n",
    "    ret,rvec,tvec = estimate_pose(corners,ids,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff']) #estimates the pose of the boarD!\n",
    "    if not ret:\n",
    "        raise Exception('Couldn\\'t estimate pose!')\n",
    "    \n",
    "    ext = np.concatenate((\n",
    "        np.concatenate((\n",
    "            cv2.Rodrigues(rvec)[0],tvec\n",
    "        ), axis=1),\n",
    "        np.array([0,0,0,1]).reshape((1,4))\n",
    "    ),axis=0)\n",
    "    \n",
    "    \n",
    "#     pts = xyz_to_xy(np.array(board.objPoints).reshape((1,-1,3)),ext,intrinsics[i]).reshape((-1,2))\n",
    "    \n",
    "#     pts = undistort_points(pts,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff']).reshape((-1,2))\n",
    "#     print(pts.shape)\n",
    "    frame = cv2.aruco.drawAxis(frame,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff'], rvec, tvec, .5)\n",
    "#     frame = undistort_image(frame,intrinsics[i]['camera_mat'],intrinsics[i]['dist_coeff'])\n",
    "     \n",
    "    ims[i].set_data(frame)\n",
    "#     axs[i].scatter(pts[:,0],pts[:,1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e648e24-2f64-416e-b276-7201c4d7add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs,rvecs,tvecs = np.load('pairs1.npy').astype(int), np.load('rvecs1.npy'), np.load('tvecs1.npy')\n",
    "p2,r2,t2 = np.load('pairs_new.npy').astype(int), np.load('rvecs_new.npy'), np.load('tvecs_new.npy')\n",
    "p2 *= 3\n",
    "r2 = np.concatenate((r2[:,0,:,:].reshape(-1,1,3,1), np.zeros((r2.shape[0],2,3,1)), r2[:,-1,:,:].reshape(-1,1,3,1)), axis=1)\n",
    "t2 = np.concatenate((t2[:,0,:,:].reshape(-1,1,3,1), np.zeros((t2.shape[0],2,3,1)), t2[:,-1,:,:].reshape(-1,1,3,1)), axis=1)\n",
    "\n",
    "pairs = np.concatenate((pairs, p2),axis=0)\n",
    "rvecs = np.concatenate((rvecs, r2),axis=0)\n",
    "tvecs = np.concatenate((tvecs, t2),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38880da4-90a1-4047-a3d5-ee99b3984fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7029, 4, 3, 1) (1854, 2, 3, 1) (7029, 4, 3, 1) (1854, 2, 3, 1) (7029,) (1854,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa9501-6f60-4714-b8c0-79e30cf48846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exts[0,0]) #pose of board (camera frame)\n",
    "# print(exts_i[0,0]) #pose of camera (board frame)\n",
    "# print(np.linalg.norm(exts[0,0,:3,3]), np.linalg.norm(exts_i[0,0,:3,3])) #distance from origin -- must be equal\n",
    "# print(np.matmul(-exts_i[0,0,:3,:3].T, exts_i[0,0,:3,3]), np.matmul(-exts[0,0,:3,:3].T, exts[0,0,:3,3])) #retrieves the translation of the other view\n",
    "\n",
    "# print(np.matmul(exts[0,0], np.concatenate((np.matmul(-exts[0,0,:3,:3].T, exts[0,0,:3,3]), np.array(1.0)[np.newaxis]), axis=0))) #position of camera in camera view -- origin\n",
    "# print(np.matmul(exts_i[0,0], np.concatenate((np.matmul(-exts_i[0,0,:3,:3].T, exts_i[0,0,:3,3]), np.array(1.0)[np.newaxis]), axis=0))) #position of board in board view -- origin\n",
    "\n",
    "# print(np.matmul(exts[0,0], np.concatenate((np.matmul(-exts[0,1,:3,:3].T, exts[0,1,:3,3]), np.array(1.0)[np.newaxis]), axis=0))) #position of camera1 in camera0 view -- goal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2ed9b1-2431-4d91-b21e-049898bc39e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237, 2, 4)\n",
      "(1237, 2, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6659fa32faae434ab65b4502e07baf42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.close('all')\n",
    "exts = np.array([[\n",
    "    np.concatenate(\n",
    "        (cv2.Rodrigues(r[i])[0], t[i]),\n",
    "        axis = 1) for i in [0,p]\n",
    "] for r,t,p in zip(rvecs, tvecs, pairs) if p])\n",
    "\n",
    "exts = np.concatenate((exts, np.tile([0,0,0,1], (*exts.shape[:2],1,1))), axis=2)\n",
    "#pose of the board in the camera's reference frame\n",
    "\n",
    "o = np.array(1.0)[np.newaxis]\n",
    "pos = np.array([[np.matmul(f[0], np.concatenate((np.matmul(-e[:3,:3].T, e[:3,3]), o), axis=0)) for e in f] for f in exts])\n",
    "print(pos.shape)\n",
    "\n",
    "pos /= pos[:,:,[-1]]\n",
    "pos = pos[:,:,:-1]\n",
    "print(pos.shape)\n",
    "#position of the camera in camera 0's reference frame\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(*pos[:,0].reshape((-1,3)).T,color='c')\n",
    "# ax.quiver(*pos[:,0].reshape((-1,3)).T, *(pos[:,0] + r[:,0]).reshape((-1,3)).T,color='c')\n",
    "\n",
    "cmap = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "c = np.array([cmap[p-1] for p in pairs if p])\n",
    "\n",
    "ax.scatter(*pos[:,1].reshape((-1,3)).T, color=c)\n",
    "# ax.quiver(*pos[:,1].reshape((-1,3)).T, *(pos[:,1] + r[:,1]).reshape((-1,3)).T, colors=c)#, cmap='prism')\n",
    "\n",
    "#bounding box\n",
    "X,Y,Z = pos.reshape(-1,3).T\n",
    "max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max()\n",
    "Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X.max()+X.min())\n",
    "Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y.max()+Y.min())\n",
    "Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z.max()+Z.min())\n",
    "\n",
    "for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "    ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355f68c-72dd-46fd-bd86-982d238451ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
