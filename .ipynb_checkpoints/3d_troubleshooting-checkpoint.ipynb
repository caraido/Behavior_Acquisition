{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17391290: 17391290, 17391304: 17391304, 19412282: 19412282, 21259803: 21259803}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as wgt\n",
    "import toml\n",
    "from re import match, search\n",
    "# from kalman_filter import undistort_points\n",
    "%matplotlib widget\n",
    "\n",
    "ROOTDIR = r'D:\\Desktop\\1076\\662_2021-09-09_male_unknown_social_status_habituation'\n",
    "# CONFIG_DIR = r'C:\\Users\\SchwartzLab\\PycharmProjects\\bahavior_rig\\config_archive\\2021-09-22-18-10-46_v3_config'\n",
    "CONFIG_DIR = os.path.join(ROOTDIR,'config')\n",
    "\n",
    "CAMERAS = [int(match('camera_(\\d+).MOV',i).group(1)) for i in os.listdir(os.path.join(ROOTDIR,'raw'))]\n",
    "TOP_CAMERA = 17391304\n",
    "MARKERS = ['nose','left_ear','right_ear','skull_base','left_hip','right_hip','tail_base','tail_end']\n",
    "MARKER_COLORS = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[1,0,1],[0,1,1],[1,1,1],[1,.5,0]])\n",
    "CAMERA_COLORS = np.array([[1,0,0,],[0,1,0],[0,0,1],[1,1,0]])\n",
    "\n",
    "#this is a hacky bit of code to account for mismatches in the videos and the calibration version\n",
    "CONFIG_CAMERAS =[search(r'_(\\d+).toml', i) for i in os.listdir(CONFIG_DIR)]\n",
    "CONFIG_CAMERAS = {int(i.group(1)) for i in CONFIG_CAMERAS if i is not None}\n",
    "CONFIG_MAP = {k:k for k in CAMERAS if k in CONFIG_CAMERAS}\n",
    "CONFIG_MAP = {**CONFIG_MAP, **{k:v for k,v in zip([c for c in CAMERAS if c not in CONFIG_CAMERAS], [c for c in CONFIG_CAMERAS if c not in CAMERAS])}}\n",
    "print(CONFIG_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_ind = [i for i,c in enumerate(CAMERAS) if c==TOP_CAMERA][0]\n",
    "#load the pose, videos, calibration\n",
    "pose = []\n",
    "caps = []\n",
    "extrs = np.array(list(toml.load(os.path.join(CONFIG_DIR, 'config_extrinsic.toml'))['extrinsic'].values())).astype(float)\n",
    "intrs = []\n",
    "nK = []\n",
    "\n",
    "for i in range(4):\n",
    "    caps.append(cv2.VideoCapture(os.path.join(ROOTDIR,'raw',f'camera_{CAMERAS[i]}.MOV')))\n",
    "    intrs.append(toml.load(os.path.join(CONFIG_DIR, f'config_intrinsic_{CONFIG_MAP[CAMERAS[i]]}.toml')))\n",
    "    intrs[i]['camera_mat'] = np.array(intrs[i]['camera_mat'])\n",
    "    intrs[i]['dist_coeff'] = np.array(intrs[i]['dist_coeff'])\n",
    "    \n",
    "    \n",
    "    if i==top_ind:\n",
    "        fname = f'camera_17391304DLC_dlcrnetms5_HipsDontLieBacksDoOct27shuffle1_200000_el_filtered.csv'\n",
    "        undistortPoints = cv2.undistortPoints\n",
    "        nK.append(cv2.getOptimalNewCameraMatrix(intrs[i]['camera_mat'],intrs[i]['dist_coeff'],(1280,1024),1)[0])\n",
    "    else:\n",
    "        fname = f'camera_{CAMERAS[i]}DLC_dlcrnetms5_SideCamera3Jan27shuffle1_200000_el_filtered.csv'\n",
    "        undistortPoints = cv2.fisheye.undistortPoints\n",
    "        nK.append(cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(intrs[i]['camera_mat'], intrs[i]['dist_coeff'], (1280,1024),np.eye(3), balance=.5))\n",
    "    \n",
    "    pose.append(pd.read_csv(os.path.join(ROOTDIR, 'DLC', fname), header = [1,2,3]).center_mouse[MARKERS])\n",
    "    # for c in pose[i].columns.get_level_values(0).unique():\n",
    "    #     pose[i].loc[:,(c,['x','y'])] = undistortPoints(pose[i].loc[:,(c,['x','y'])].to_numpy().reshape(-1,1,2), intrs[i]['camera_mat'],intrs[i]['dist_coeff']).squeeze()\n",
    "\n",
    "frame_count = int(min([c.get(cv2.CAP_PROP_FRAME_COUNT) for c in caps]))\n",
    "data = pd.read_csv(os.path.join(ROOTDIR, 'DLC', 'output_3d_data_kalman.csv'),header=[0,1]).to_numpy()\n",
    "# print(pd.read_csv(os.path.join(ROOTDIR, 'DLC', 'output_3d_data_kalman.csv'),header=[0,1]).head)\n",
    "# print(data.shape,frame_count)\n",
    "pose3 = np.moveaxis(data.reshape((-1,6,data.shape[1]//6)), 1, 2)\n",
    "\n",
    "# print(data.shape, pose3.shape, frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.4748839477658551e-01  8.3645364815636725e-01 -2.4530635353813352e-02\n",
      "   2.8357764990488277e+00]\n",
      " [ 4.7662023035934940e-02 -1.9029054080005100e-03  9.9886170740054414e-01\n",
      "  -3.0848486711250150e+01]\n",
      " [ 8.3599571461785116e-01 -5.4801393724250547e-01 -2.8140535328166238e-02\n",
      "   6.1993351063204463e+00]\n",
      " [ 0.0000000000000000e+00  0.0000000000000000e+00  0.0000000000000000e+00\n",
      "   1.0000000000000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def reorient(extr,theta):\n",
    "    #adjusts the angle of the camera about its principal axis\n",
    "    # get the lookat and up vectors\n",
    "    lookAt = -extr[2,:3]\n",
    "    up = extr[1,:3]\n",
    "    \n",
    "    #rotate the up vector by the given angle\n",
    "    up = np.array([[np.cos(theta),np.sin(theta),0],[-np.sin(theta),np.cos(theta),0],[0,0,1]]) @ up\n",
    "    \n",
    "    #reform the camera matrix\n",
    "    s = np.cross(lookAt,up)\n",
    "    s = s / np.linalg.norm(s)    \n",
    "    return np.array([s,up,-lookAt])    \n",
    "    \n",
    "# extrs[-1][:3,:3] = reorient(extrs[-1][:3,:3],0.4)\n",
    "# np.set_printoptions(precision=16)\n",
    "# print(extrs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xyz_to_xy(xyz, extrinsic, intrinsic, undistort=True):\n",
    "    rvec, _ = cv2.Rodrigues(extrinsic[0:3, 0:3])\n",
    "    tvec = extrinsic[0:3, 3]\n",
    "    if undistort:\n",
    "        dcs = np.zeros(intrinsic['dist_coeff'].shape)\n",
    "    else:\n",
    "        dcs = intrinsic['dist_coeff']\n",
    "    if len(dcs) == 4:\n",
    "        xy, _ = cv2.fisheye.projectPoints(xyz, rvec, tvec, intrinsic['camera_mat'], dcs)\n",
    "    else:\n",
    "        xy, _ = cv2.projectPoints(xyz, rvec, tvec, intrinsic['camera_mat'], dcs)\n",
    "        \n",
    "    return xy\n",
    "\n",
    "def xy_to_xyz(xy, d, extrinsic, intrinsic, undistort=True):\n",
    "    #each pixel maps to a line segment in world coordinates, with range defined by d\n",
    "    #xy: (1-by-1-by-2)\n",
    "    #d: (N-by-1)\n",
    "    #xyz: (N-by-1-by-2)\n",
    "\n",
    "    xy = xy.reshape((1,1,2))\n",
    "    d = d.reshape((-1,1,1))\n",
    "\n",
    "    cm = intrinsic['camera_mat']\n",
    "\n",
    "    #1: undistort the points\n",
    "    if undistort:\n",
    "        if len(intrinsic['dist_coeff']) == 4:\n",
    "            undistortPoints = cv2.fisheye.undistortPoints\n",
    "        else:\n",
    "            undistortPoints = cv2.undistortPoints\n",
    "        xy = undistortPoints(xy, cm, intrinsic['dist_coeff'])\n",
    "\n",
    "    #2: apply the inverted camera matrix\n",
    "    xyh = cv2.transform(xy, np.linalg.inv(cm))\n",
    "\n",
    "    # #3: map the depth\n",
    "    xyh = np.concatenate((\n",
    "        xy[:,:,:3] * d,\n",
    "        d\n",
    "    ), axis=2)\n",
    "\n",
    "    #4: apply the inverted extrinsic matrix\n",
    "    xyz = cv2.transform(xyh, np.linalg.inv(extrinsic))\n",
    "    xyz = xyz [:,:,:3] / xyz[:,:,3].reshape(-1,1,1)\n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b3d92b073c42c4826b325bee9a07c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=375, max=4296), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_projections():\n",
    "    output = wgt.Output()\n",
    "    with output:\n",
    "        fig,axs = plt.subplots(2,2, figsize=(14,8))\n",
    "    \n",
    "    axs = axs.flatten()\n",
    "    ims = [None for _ in range(4)]\n",
    "    marks = [None for _ in range(4)]\n",
    "    cams = [[None for __ in range(4)] for _ in range(4)]\n",
    "    rays = [[[None for ___ in range(len(MARKERS))]for __ in range(4)] for _ in range(4)]\n",
    "    d3 = [None for _ in range(4)]\n",
    "\n",
    "    frame_init = 375\n",
    "\n",
    "    for i in range(4):\n",
    "        if i==top_ind:\n",
    "            undistortImage = cv2.undistort\n",
    "        else:\n",
    "            undistortImage = cv2.fisheye.undistortImage\n",
    "\n",
    "        caps[i].set(cv2.CAP_PROP_POS_FRAMES, frame_init) #seek to a common frame_init...\n",
    "        # ims[i] = axs[i].imshow(undistortImage(caps[i].read()[1], intrs[i]['camera_mat'], intrs[i]['dist_coeff'], None, nK[i]))\n",
    "        ims[i] = axs[i].imshow(caps[i].read()[1])\n",
    "        marks[i] = axs[i].scatter(\n",
    "            pose[i].iloc[frame_init, pose[i].columns.get_level_values(1)=='x'],\n",
    "            pose[i].iloc[frame_init, pose[i].columns.get_level_values(1)=='y'],\n",
    "            c=MARKER_COLORS\n",
    "        )\n",
    "        p3 = xyz_to_xy(pose3[frame_init].reshape(-1,1,3), extrs[i], intrs[i])\n",
    "        d3[i] = axs[i].scatter(p3[:,:,0], p3[:,:,1],marker='x', color = 'red')\n",
    "\n",
    "        for j in range(4):\n",
    "            if i==j: continue\n",
    "            pos3 = -extrs[j][:3,:3].T @ extrs[j][:3,3]\n",
    "            # pos2 = xyz_to_xy(pos3.reshape((1,1,3)), extrs[i],{'camera_mat':nK[i], 'dist_coeff': intrs[i]['dist_coeff']}, undistort=False).flatten()\n",
    "            pos2 = xyz_to_xy(pos3.reshape((1,1,3)), extrs[i],intrs[i], undistort=True).flatten()\n",
    "            cams[i][j] = axs[i].scatter(pos2[0], pos2[1], s=100, linewidths=3, color='#00000000', edgecolors=CAMERA_COLORS[j])\n",
    "            extent = 35 if j==top_ind else 5\n",
    "            for k in range(len(MARKERS)):\n",
    "                xyz = xy_to_xyz(\n",
    "                np.array([pose[j][MARKERS[k]].x[frame_init], pose[j][MARKERS[k]].y[frame_init]]),\n",
    "                np.linspace(0,extent,100), extrs[j], intrs[j], undistort=True\n",
    "                )\n",
    "                uv = xyz_to_xy(xyz, extrs[i], intrs[i], undistort = True)\n",
    "\n",
    "                rays[i][j][k] = axs[i].plot(uv[:,:,0],uv[:,:,1],c=MARKER_COLORS[k])[0]\n",
    "        axs[i].set_xlim((0,1280))\n",
    "        axs[i].set_ylim((1024,0))\n",
    "\n",
    "    def update(change):\n",
    "        if change['name']!='value':\n",
    "            return\n",
    "        frame = change['new']\n",
    "        for i in range(4):\n",
    "            if i==top_ind:\n",
    "                undistortImage = cv2.undistort\n",
    "            else:\n",
    "                undistortImage = cv2.fisheye.undistortImage\n",
    "\n",
    "            caps[i].set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "            #ims[i].set_data(undistortImage(caps[i].read()[1], intrs[i]['camera_mat'], intrs[i]['dist_coeff'], None, nK[i]))\n",
    "            ims[i].set_data(caps[i].read()[1])\n",
    "            marks[i].set_offsets(np.concatenate((\n",
    "                pose[i].iloc[frame, pose[i].columns.get_level_values(1)=='x'].to_numpy().reshape(-1,1),\n",
    "                pose[i].iloc[frame, pose[i].columns.get_level_values(1)=='y'].to_numpy().reshape(-1,1)\n",
    "            ), axis=1))\n",
    "\n",
    "            p3 = xyz_to_xy(pose3[frame].reshape(-1,1,3), extrs[i], intrs[i]).reshape((-1,2))\n",
    "            d3[i].set_offsets(p3)\n",
    "\n",
    "            for j in range(4):\n",
    "                if i==j: continue\n",
    "                extent = 35 if j==top_ind else 5\n",
    "                for k in range(len(MARKERS)):\n",
    "                    xyz = xy_to_xyz(\n",
    "                    np.array([pose[j][MARKERS[k]].x[frame], pose[j][MARKERS[k]].y[frame]]),\n",
    "                    np.linspace(0,extent,100), extrs[j], intrs[j], undistort = True\n",
    "                    )\n",
    "                    uv = xyz_to_xy(xyz, extrs[i], intrs[i], undistort = True)\n",
    "                    rays[i][j][k].set_data(uv[:,:,0],uv[:,:,1])\n",
    "\n",
    "        \n",
    "    \n",
    "    frame_select = wgt.IntSlider(value=frame_init, min=0, max=frame_count)\n",
    "    frame_select.observe(update)\n",
    "\n",
    "    display(wgt.VBox([frame_select, output]))\n",
    "\n",
    "plt.close('all')\n",
    "show_projections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c4d7fa293cdf30b7a522abb3f04430f5b9bc23ba767eb021569d8631c230f37"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
